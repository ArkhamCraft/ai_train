{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看FashionMNIST原始数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:32.363026Z",
     "start_time": "2025-06-26T01:43:29.447990Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from classificatiom_model import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from classificatiom_model import evaluate_classification_model as evaluate_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据并处理为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:32.407799Z",
     "start_time": "2025-06-26T01:43:32.363026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别数量: 10\n",
      "类别名称: ['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9']\n",
      "图像形状: torch.Size([3, 128, 128])\n",
      "标签: 0 (类别: n0)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./archive/\")\n",
    "\n",
    "# 定义数据预处理\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # 调整图像大小为128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化，使用ImageNet的均值和标准差\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # 调整图像大小为128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化，使用ImageNet的均值和标准差\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 使用ImageFolder加载数据\n",
    "# ImageFolder假设数据集按照如下方式组织：root/class/image.jpg\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=DATA_DIR / 'training',\n",
    "    transform=data_transforms['training']\n",
    ")\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=DATA_DIR / 'validation',\n",
    "    transform=data_transforms['validation']\n",
    ")\n",
    "\n",
    "# 打印类别信息\n",
    "class_names = train_dataset.classes\n",
    "print(f\"类别数量: {len(class_names)}\")\n",
    "print(f\"类别名称: {class_names}\")\n",
    "\n",
    "# 查看一个样本\n",
    "img, label = train_dataset[0]\n",
    "print(f\"图像形状: {img.shape}\")  # 应该是[3, 128, 128]\n",
    "print(f\"标签: {label} (类别: {class_names[label]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别数量: 10\n",
      "类别名称: ['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9']\n",
      "图像形状: torch.Size([3, 128, 128])\n",
      "标签: 0 (类别: n0)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"./archive/\")\n",
    "\n",
    "# 自定义数据集类，继承ImageFolder\n",
    "class MonkeyDataset(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__(root=root, transform=transform)\n",
    "        \n",
    "    # def __getitem__(self, index):\n",
    "    #     # 调用父类的__getitem__方法获取图像和标签\n",
    "    #     img, label = super(MonkeyDataset, self).__getitem__(index)\n",
    "    #     return img, label\n",
    "\n",
    "# 定义数据预处理\n",
    "data_transforms = {\n",
    "    'training': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # 调整图像大小为128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.4363, 0.4328, 0.3291], std=[0.2085, 0.2032, 0.1988])  # 标准化，使用ImageNet的均值和标准差\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # 调整图像大小为128x128\n",
    "        transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "        transforms.Normalize(mean=[0.4363, 0.4328, 0.3291], std=[0.2085, 0.2032, 0.1988])  # 标准化，使用ImageNet的均值和标准差\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 使用自定义的MonkeyDataset加载数据\n",
    "train_dataset = MonkeyDataset(\n",
    "    root=DATA_DIR / 'training',\n",
    "    transform=data_transforms['training']\n",
    ")\n",
    "\n",
    "test_dataset = MonkeyDataset(\n",
    "    root=DATA_DIR / 'validation',\n",
    "    transform=data_transforms['validation']\n",
    ")\n",
    "\n",
    "# 打印类别信息\n",
    "class_names = train_dataset.classes\n",
    "print(f\"类别数量: {len(class_names)}\")\n",
    "print(f\"类别名称: {class_names}\")\n",
    "\n",
    "# 查看一个样本\n",
    "img, label = train_dataset[0]\n",
    "print(f\"图像形状: {img.shape}\")  # 应该是[3, 128, 128]\n",
    "print(f\"标签: {label} (类别: {class_names[label]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.5299e-04,  3.6267e-05, -6.5391e-07]),\n",
       " tensor([0.9999, 0.9999, 1.0002]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_mean_std(ds):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for img, _ in ds:\n",
    "        mean += img.mean(dim=(1, 2)) #dim=(1, 2)表示在通道维度上求平均\n",
    "        std += img.std(dim=(1, 2))  #dim=(1, 2)表示在通道维度上求标准差\n",
    "    mean /= len(ds)\n",
    "    std /= len(ds)\n",
    "    return mean, std\n",
    "cal_mean_std(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把数据集划分为训练集55000和验证集5000，并给DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.144223Z",
     "start_time": "2025-06-26T01:43:33.135368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 1097\n",
      "测试集大小: 272\n",
      "批次大小: 32\n",
      "训练批次数: 35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 打印数据集大小信息\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n",
    "print(f\"批次大小: {batch_size}\")\n",
    "print(f\"训练批次数: {len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.148120Z",
     "start_time": "2025-06-26T01:43:33.145230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55040"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64*860"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100])\n"
     ]
    }
   ],
   "source": [
    "#理解每个接口的方法，单独写例子\n",
    "import torch.nn as nn\n",
    "m=nn.BatchNorm1d(100)\n",
    "x=torch.randn(20,100)\n",
    "print(m(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解析padding超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([4, 1, 28, 28])\n",
      "输出形状: torch.Size([4, 16, 14, 14])\n",
      "参数数量: 416\n"
     ]
    }
   ],
   "source": [
    "# 初始化一个5*5的卷积层，保持输入输出图像尺寸不变\n",
    "# 为了保持尺寸不变，需要设置适当的padding\n",
    "# 对于kernel_size=5的卷积，需要padding=2才能保持尺寸不变\n",
    "\n",
    "# 示例：创建一个单通道输入，16通道输出的卷积层\n",
    "in_channels = 1\n",
    "out_channels = 16\n",
    "kernel_size = 5\n",
    "padding = 2  # padding = (kernel_size - 1) / 2 可以保持尺寸不变\n",
    "\n",
    "# 创建卷积层\n",
    "# padding='same' 表示使用动态padding，保持输入输出图像尺寸不变,为same时，步长只能为1\n",
    "# padding='valid' 表示不使用padding，输出图像尺寸会变小\n",
    "conv = nn.Conv2d(in_channels, out_channels, kernel_size=5, padding=2,stride=2)\n",
    "\n",
    "# 创建一个示例输入(批次大小为4，单通道，28x28的图像)\n",
    "x = torch.randn(4, 1, 28, 28)\n",
    "\n",
    "# 前向传播\n",
    "output = conv(x)\n",
    "\n",
    "# 打印输入和输出的形状，验证尺寸是否保持不变\n",
    "print(f\"输入形状: {x.shape}\")\n",
    "print(f\"输出形状: {output.shape}\")\n",
    "print(f\"参数数量: {sum(p.numel() for p in conv.parameters())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128//2//2//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.152657Z",
     "start_time": "2025-06-26T01:43:33.148120Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 第一组卷积层 - 32个卷积核\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1) # 输入通道数，输出通道数代表的是卷积核的个数\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 第二组卷积层 - 64个卷积核\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        \n",
    "        # 第三组卷积层 - 128个卷积核\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        \n",
    "        # 计算全连接层的输入特征数\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "        # 初始化权重\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"使用 xavier 均匀分布来初始化卷积层和全连接层的权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape [batch size, 1, 28, 28]\n",
    "        \n",
    "        # 第一组卷积层\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # print(f\"conv1后的形状: {x.shape}\")\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # print(f\"conv2后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool1后的形状: {x.shape}\")\n",
    "        \n",
    "        # 第二组卷积层\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print(f\"conv3后的形状: {x.shape}\")\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # print(f\"conv4后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool2后的形状: {x.shape}\")\n",
    "        \n",
    "        # 第三组卷积层\n",
    "        x = F.relu(self.conv5(x))\n",
    "        # print(f\"conv5后的形状: {x.shape}\")\n",
    "        x = F.relu(self.conv6(x))\n",
    "        # print(f\"conv6后的形状: {x.shape}\")\n",
    "        x = self.pool(x)\n",
    "        # print(f\"pool3后的形状: {x.shape}\")\n",
    "        \n",
    "        # 展平\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(f\"展平后的形状: {x.shape}\")\n",
    "        \n",
    "        # 全连接层\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # print(f\"fc1后的形状: {x.shape}\")\n",
    "        x = self.fc2(x)\n",
    "        # print(f\"fc2后的形状: {x.shape}\")\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.185031Z",
     "start_time": "2025-06-26T01:43:33.152657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次图像形状: torch.Size([32, 3, 128, 128])\n",
      "批次标签形状: torch.Size([32])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# 从train_loader获取第一个批次的数据\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 查看批次数据的形状\n",
    "print(\"批次图像形状:\", images.shape)\n",
    "print(\"批次标签形状:\", labels.shape)\n",
    "\n",
    "\n",
    "print('-'*100)\n",
    "# 进行前向传播\n",
    "with torch.no_grad():  # 不需要计算梯度\n",
    "    outputs = model(images)\n",
    "    \n",
    "\n",
    "print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.203053Z",
     "start_time": "2025-06-26T01:43:33.199532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要求梯度的参数总量: 8678442\n",
      "模型总参数量: 8678442\n",
      "\n",
      "各层参数量明细:\n",
      "conv1.weight: 864 参数\n",
      "conv1.bias: 32 参数\n",
      "conv2.weight: 9216 参数\n",
      "conv2.bias: 32 参数\n",
      "conv3.weight: 18432 参数\n",
      "conv3.bias: 64 参数\n",
      "conv4.weight: 36864 参数\n",
      "conv4.bias: 64 参数\n",
      "conv5.weight: 73728 参数\n",
      "conv5.bias: 128 参数\n",
      "conv6.weight: 147456 参数\n",
      "conv6.bias: 128 参数\n",
      "fc1.weight: 8388608 参数\n",
      "fc1.bias: 256 参数\n",
      "fc2.weight: 2560 参数\n",
      "fc2.bias: 10 参数\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数量\n",
    "# 统计需要求梯度的参数总量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"需要求梯度的参数总量: {total_params}\")\n",
    "\n",
    "# 统计所有参数总量\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {all_params}\")\n",
    "\n",
    "# 查看每层参数量明细\n",
    "print(\"\\n各层参数量明细:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} 参数\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294912"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*3*3*256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各层参数量明细:\n",
    "conv1.weight: 288 参数 3*3*1*32\n",
    "conv1.bias: 32 参数\n",
    "conv2.weight: 9216 参数 3*3*32*32\n",
    "conv2.bias: 32 参数  \n",
    "conv3.weight: 18432 参数 3*3*32*64\n",
    "conv3.bias: 64 参数\n",
    "conv4.weight: 36864 参数  3*3*64*64\n",
    "conv4.bias: 64 参数\n",
    "conv5.weight: 73728 参数\n",
    "conv5.bias: 128 参数\n",
    "conv6.weight: 147456 参数\n",
    "conv6.bias: 128 参数\n",
    "fc1.weight: 294912 参数 128*3*3*256\n",
    "fc1.bias: 256 参数\n",
    "fc2.weight: 2560 参数\n",
    "fc2.bias: 10 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:33.217395Z",
     "start_time": "2025-06-26T01:43:33.203561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight',\n",
       "              tensor([[[[ 0.0351,  0.0746,  0.1303],\n",
       "                        [-0.1172,  0.1241, -0.1037],\n",
       "                        [-0.0206,  0.0391,  0.0618]],\n",
       "              \n",
       "                       [[-0.1304, -0.0191, -0.0673],\n",
       "                        [-0.0993,  0.0699,  0.0429],\n",
       "                        [ 0.0922, -0.1333,  0.0147]],\n",
       "              \n",
       "                       [[ 0.1052,  0.0411, -0.0455],\n",
       "                        [-0.0100, -0.0093,  0.0203],\n",
       "                        [ 0.0313, -0.0346,  0.0781]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1358,  0.0592, -0.1285],\n",
       "                        [ 0.1035,  0.1199,  0.0384],\n",
       "                        [ 0.1374,  0.0045,  0.0797]],\n",
       "              \n",
       "                       [[ 0.0474, -0.0621,  0.0359],\n",
       "                        [-0.1171, -0.0058, -0.0800],\n",
       "                        [-0.1248, -0.0620, -0.0109]],\n",
       "              \n",
       "                       [[-0.0725, -0.0384, -0.1099],\n",
       "                        [ 0.0006,  0.0139,  0.0328],\n",
       "                        [-0.0685,  0.1255,  0.0873]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0744,  0.0704,  0.1044],\n",
       "                        [ 0.0636,  0.0686,  0.1342],\n",
       "                        [ 0.1073,  0.1074, -0.1016]],\n",
       "              \n",
       "                       [[-0.1171, -0.0621, -0.0618],\n",
       "                        [ 0.0826, -0.0635,  0.0756],\n",
       "                        [ 0.0874,  0.0326, -0.1283]],\n",
       "              \n",
       "                       [[ 0.1219, -0.0964,  0.0181],\n",
       "                        [-0.1018, -0.0783, -0.1021],\n",
       "                        [ 0.0269, -0.0283, -0.0642]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0120, -0.0834,  0.0607],\n",
       "                        [ 0.0484,  0.0952,  0.0121],\n",
       "                        [ 0.1108, -0.1003, -0.0286]],\n",
       "              \n",
       "                       [[-0.0429,  0.1255,  0.0667],\n",
       "                        [-0.0418,  0.0781, -0.0495],\n",
       "                        [-0.0337, -0.0122,  0.0866]],\n",
       "              \n",
       "                       [[-0.0675,  0.0816, -0.0380],\n",
       "                        [ 0.0146,  0.1283,  0.1144],\n",
       "                        [-0.0812,  0.1003,  0.0898]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0945,  0.0773, -0.1370],\n",
       "                        [-0.1177, -0.0712, -0.0126],\n",
       "                        [ 0.1179,  0.0897, -0.0603]],\n",
       "              \n",
       "                       [[-0.1358, -0.1265,  0.0235],\n",
       "                        [ 0.0718, -0.1111, -0.0400],\n",
       "                        [ 0.0897,  0.1134, -0.0940]],\n",
       "              \n",
       "                       [[-0.1159, -0.0033,  0.0676],\n",
       "                        [ 0.0406,  0.0752,  0.0718],\n",
       "                        [-0.1268, -0.1058,  0.1033]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0373, -0.0689, -0.0146],\n",
       "                        [ 0.0653,  0.0969,  0.0491],\n",
       "                        [-0.1240,  0.0256, -0.0481]],\n",
       "              \n",
       "                       [[-0.0023,  0.1063,  0.0856],\n",
       "                        [ 0.0718,  0.0071, -0.1051],\n",
       "                        [-0.0667, -0.1252, -0.0541]],\n",
       "              \n",
       "                       [[-0.0317,  0.0869,  0.0417],\n",
       "                        [-0.1025,  0.1123,  0.0854],\n",
       "                        [ 0.0460,  0.1373,  0.0869]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1326,  0.0942,  0.0550],\n",
       "                        [-0.0105,  0.0113,  0.0237],\n",
       "                        [ 0.1018, -0.0728,  0.1049]],\n",
       "              \n",
       "                       [[ 0.0890,  0.0794,  0.1166],\n",
       "                        [ 0.0161,  0.0470, -0.0213],\n",
       "                        [ 0.0190,  0.0195, -0.0769]],\n",
       "              \n",
       "                       [[-0.0735, -0.0213, -0.1348],\n",
       "                        [ 0.1204,  0.0734, -0.1375],\n",
       "                        [-0.0329, -0.0321, -0.0975]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0440, -0.1307,  0.0571],\n",
       "                        [ 0.0665,  0.1253, -0.0104],\n",
       "                        [ 0.0652, -0.0981,  0.0060]],\n",
       "              \n",
       "                       [[-0.0636, -0.0847, -0.1141],\n",
       "                        [ 0.0352,  0.0955, -0.0911],\n",
       "                        [-0.0015,  0.0260,  0.1013]],\n",
       "              \n",
       "                       [[-0.0537, -0.0733,  0.1363],\n",
       "                        [-0.0846, -0.0094, -0.1101],\n",
       "                        [-0.0447, -0.1377,  0.1287]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0644, -0.1122, -0.0121],\n",
       "                        [ 0.0512,  0.0774,  0.1044],\n",
       "                        [-0.0540, -0.0884,  0.0266]],\n",
       "              \n",
       "                       [[-0.0027, -0.0328,  0.1150],\n",
       "                        [ 0.0493, -0.0799, -0.0305],\n",
       "                        [ 0.0305, -0.0075, -0.0021]],\n",
       "              \n",
       "                       [[-0.1146,  0.0107,  0.0464],\n",
       "                        [ 0.0297,  0.1206, -0.1053],\n",
       "                        [ 0.1316,  0.0499,  0.0303]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1079, -0.1253, -0.0138],\n",
       "                        [ 0.0178,  0.1140, -0.0508],\n",
       "                        [-0.0599, -0.0553,  0.0672]],\n",
       "              \n",
       "                       [[-0.0545,  0.0663, -0.0298],\n",
       "                        [ 0.0867,  0.0334,  0.1032],\n",
       "                        [ 0.0237, -0.0947, -0.0679]],\n",
       "              \n",
       "                       [[ 0.0846, -0.0559,  0.1272],\n",
       "                        [ 0.0804,  0.1079,  0.0953],\n",
       "                        [ 0.0293, -0.1042, -0.0577]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0697,  0.0520,  0.0231],\n",
       "                        [-0.0890, -0.1196, -0.0283],\n",
       "                        [ 0.0049, -0.0933,  0.0294]],\n",
       "              \n",
       "                       [[-0.0426,  0.1197, -0.0660],\n",
       "                        [-0.1349,  0.0993,  0.0404],\n",
       "                        [-0.0903, -0.0736,  0.1191]],\n",
       "              \n",
       "                       [[-0.0046,  0.0340,  0.0700],\n",
       "                        [ 0.0482, -0.0143,  0.1069],\n",
       "                        [ 0.0730,  0.1032,  0.0940]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0415, -0.1368,  0.0280],\n",
       "                        [ 0.1304,  0.0018,  0.0434],\n",
       "                        [ 0.0955, -0.1316,  0.0930]],\n",
       "              \n",
       "                       [[ 0.0160, -0.1269,  0.0958],\n",
       "                        [ 0.0813, -0.0870, -0.0894],\n",
       "                        [-0.1340,  0.1233,  0.1363]],\n",
       "              \n",
       "                       [[ 0.1257,  0.1067,  0.1125],\n",
       "                        [ 0.0780, -0.0230, -0.0869],\n",
       "                        [-0.0373, -0.0190,  0.0817]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0620,  0.0281, -0.0063],\n",
       "                        [-0.0332,  0.0815,  0.0036],\n",
       "                        [-0.0196,  0.0649, -0.1169]],\n",
       "              \n",
       "                       [[ 0.1239,  0.1038,  0.0906],\n",
       "                        [ 0.1184,  0.0263, -0.0848],\n",
       "                        [ 0.0409,  0.0308, -0.1281]],\n",
       "              \n",
       "                       [[-0.1276, -0.0101,  0.0732],\n",
       "                        [-0.0059,  0.1236, -0.0847],\n",
       "                        [-0.0543, -0.1238, -0.1124]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0648, -0.1359,  0.0094],\n",
       "                        [-0.1378,  0.1343, -0.0865],\n",
       "                        [ 0.0099, -0.0944, -0.0491]],\n",
       "              \n",
       "                       [[-0.0532, -0.0254, -0.1017],\n",
       "                        [ 0.1208,  0.0201, -0.1028],\n",
       "                        [ 0.0968, -0.0290, -0.0456]],\n",
       "              \n",
       "                       [[-0.0055,  0.1206,  0.1244],\n",
       "                        [-0.1011, -0.1304, -0.1015],\n",
       "                        [-0.0926, -0.0713,  0.0134]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0482, -0.1085,  0.0130],\n",
       "                        [-0.1346, -0.0379,  0.0155],\n",
       "                        [-0.1323,  0.1360, -0.1231]],\n",
       "              \n",
       "                       [[-0.1292, -0.0856, -0.0998],\n",
       "                        [ 0.1246, -0.0006,  0.0626],\n",
       "                        [-0.1090,  0.1003, -0.0412]],\n",
       "              \n",
       "                       [[ 0.1257, -0.0065,  0.1010],\n",
       "                        [ 0.0392,  0.0471, -0.0800],\n",
       "                        [ 0.1106,  0.0397, -0.1247]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0326,  0.0890, -0.0544],\n",
       "                        [-0.0508,  0.0107,  0.0381],\n",
       "                        [ 0.0517, -0.0275, -0.0980]],\n",
       "              \n",
       "                       [[ 0.0128,  0.0884, -0.0034],\n",
       "                        [-0.0038,  0.0982,  0.1289],\n",
       "                        [ 0.0631, -0.0431,  0.0358]],\n",
       "              \n",
       "                       [[-0.0036,  0.0181,  0.0684],\n",
       "                        [ 0.0478, -0.0862,  0.0853],\n",
       "                        [ 0.0031, -0.1056, -0.0818]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0585, -0.1179, -0.1375],\n",
       "                        [ 0.0031,  0.0889, -0.0047],\n",
       "                        [ 0.0677, -0.0866, -0.1197]],\n",
       "              \n",
       "                       [[-0.0874,  0.0126,  0.0840],\n",
       "                        [ 0.0787, -0.0270, -0.0461],\n",
       "                        [ 0.0823, -0.0988, -0.0323]],\n",
       "              \n",
       "                       [[-0.0130,  0.0313, -0.0169],\n",
       "                        [-0.1133, -0.0450,  0.0894],\n",
       "                        [-0.1189, -0.0579,  0.0391]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0897,  0.0588, -0.0588],\n",
       "                        [ 0.1254, -0.1083,  0.1331],\n",
       "                        [-0.0700,  0.0748,  0.0081]],\n",
       "              \n",
       "                       [[ 0.0362,  0.0307, -0.0269],\n",
       "                        [ 0.0210, -0.0427,  0.0545],\n",
       "                        [-0.0608, -0.0996,  0.1198]],\n",
       "              \n",
       "                       [[ 0.1203, -0.1131,  0.0193],\n",
       "                        [ 0.0053, -0.0954,  0.1270],\n",
       "                        [ 0.0751, -0.1170,  0.1277]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1138,  0.0796, -0.1239],\n",
       "                        [-0.0160,  0.1265,  0.1133],\n",
       "                        [-0.1342,  0.1313, -0.1046]],\n",
       "              \n",
       "                       [[-0.0339,  0.0582, -0.0520],\n",
       "                        [-0.0577,  0.0086, -0.0171],\n",
       "                        [ 0.0052,  0.1263, -0.0527]],\n",
       "              \n",
       "                       [[-0.1135,  0.0678,  0.0268],\n",
       "                        [ 0.1041, -0.0242, -0.0931],\n",
       "                        [ 0.0677,  0.1205, -0.0916]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0504, -0.0226, -0.0693],\n",
       "                        [-0.0080, -0.0937, -0.0117],\n",
       "                        [ 0.0509, -0.1051, -0.1076]],\n",
       "              \n",
       "                       [[ 0.1099, -0.0187, -0.1367],\n",
       "                        [-0.0671,  0.0769, -0.0757],\n",
       "                        [-0.0212, -0.0888, -0.0449]],\n",
       "              \n",
       "                       [[-0.0370,  0.0738, -0.0744],\n",
       "                        [ 0.0535,  0.1247, -0.0845],\n",
       "                        [-0.0632,  0.0096,  0.0747]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0877, -0.0324, -0.0441],\n",
       "                        [ 0.0634,  0.0071, -0.0497],\n",
       "                        [-0.0781,  0.0753,  0.0378]],\n",
       "              \n",
       "                       [[-0.1133,  0.1028, -0.1067],\n",
       "                        [-0.1136,  0.0717,  0.0407],\n",
       "                        [-0.1348,  0.0396,  0.0512]],\n",
       "              \n",
       "                       [[ 0.0787,  0.0108, -0.1200],\n",
       "                        [-0.0115, -0.0593, -0.0686],\n",
       "                        [ 0.0373,  0.0233,  0.0104]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0814, -0.1267, -0.1066],\n",
       "                        [-0.0423,  0.1333, -0.1326],\n",
       "                        [-0.0045, -0.0187,  0.0509]],\n",
       "              \n",
       "                       [[-0.0496, -0.0368,  0.1047],\n",
       "                        [ 0.0762, -0.1092,  0.0884],\n",
       "                        [-0.0967, -0.0675,  0.0935]],\n",
       "              \n",
       "                       [[ 0.0959,  0.0678, -0.1275],\n",
       "                        [ 0.0137,  0.0564,  0.0907],\n",
       "                        [ 0.1157, -0.1045, -0.0982]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0926, -0.0722, -0.0610],\n",
       "                        [ 0.1307, -0.1185,  0.0584],\n",
       "                        [-0.0745,  0.0366,  0.1099]],\n",
       "              \n",
       "                       [[ 0.0929, -0.0343, -0.0220],\n",
       "                        [-0.0051,  0.1255,  0.0165],\n",
       "                        [-0.1142,  0.1055, -0.0332]],\n",
       "              \n",
       "                       [[ 0.0948,  0.0587,  0.0961],\n",
       "                        [-0.0672, -0.0267, -0.0886],\n",
       "                        [-0.0246, -0.0933, -0.1196]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0318, -0.0377,  0.0601],\n",
       "                        [-0.1081,  0.0111,  0.0082],\n",
       "                        [-0.0385,  0.0523,  0.1197]],\n",
       "              \n",
       "                       [[ 0.0429, -0.1048, -0.1066],\n",
       "                        [ 0.0956,  0.0343, -0.0191],\n",
       "                        [-0.0641, -0.1104,  0.1014]],\n",
       "              \n",
       "                       [[ 0.0708,  0.0655,  0.0843],\n",
       "                        [ 0.0460, -0.1289, -0.1030],\n",
       "                        [ 0.0868, -0.0362, -0.0478]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0669,  0.0943,  0.0659],\n",
       "                        [ 0.1086,  0.0601,  0.0922],\n",
       "                        [-0.0383,  0.1377,  0.0289]],\n",
       "              \n",
       "                       [[-0.0321, -0.0105,  0.0783],\n",
       "                        [ 0.0629, -0.0025, -0.0331],\n",
       "                        [ 0.1015, -0.0571,  0.0379]],\n",
       "              \n",
       "                       [[ 0.1180,  0.0300, -0.0895],\n",
       "                        [ 0.0370,  0.0520,  0.1299],\n",
       "                        [ 0.0426, -0.0587, -0.1247]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0714, -0.1025, -0.0078],\n",
       "                        [ 0.0169, -0.0023,  0.1060],\n",
       "                        [-0.0348, -0.0160,  0.0680]],\n",
       "              \n",
       "                       [[-0.0368, -0.1224,  0.0964],\n",
       "                        [ 0.0048, -0.0426,  0.0498],\n",
       "                        [-0.0367, -0.0025, -0.0576]],\n",
       "              \n",
       "                       [[ 0.1201, -0.0879, -0.0351],\n",
       "                        [ 0.1079,  0.1312,  0.0431],\n",
       "                        [ 0.1201,  0.0886, -0.0942]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1086, -0.0992, -0.1103],\n",
       "                        [-0.0142, -0.0457,  0.0732],\n",
       "                        [ 0.0972,  0.0559,  0.0172]],\n",
       "              \n",
       "                       [[-0.1093,  0.0191,  0.0688],\n",
       "                        [-0.0391,  0.0129, -0.0363],\n",
       "                        [-0.0880,  0.1307, -0.0709]],\n",
       "              \n",
       "                       [[-0.1121,  0.0246,  0.0321],\n",
       "                        [ 0.1038,  0.1033, -0.1253],\n",
       "                        [ 0.0208,  0.0724,  0.0845]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1144,  0.0673, -0.0767],\n",
       "                        [ 0.0571, -0.0638,  0.0003],\n",
       "                        [ 0.0510, -0.1271,  0.0324]],\n",
       "              \n",
       "                       [[ 0.1245,  0.1048, -0.1214],\n",
       "                        [-0.0444, -0.0165, -0.1213],\n",
       "                        [-0.0029,  0.1183,  0.0316]],\n",
       "              \n",
       "                       [[ 0.0417, -0.0102,  0.0585],\n",
       "                        [-0.0743,  0.1327,  0.0881],\n",
       "                        [ 0.0130,  0.0658, -0.0048]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1058,  0.0641, -0.0535],\n",
       "                        [-0.1245,  0.1068,  0.0393],\n",
       "                        [-0.0605, -0.0664, -0.0937]],\n",
       "              \n",
       "                       [[ 0.0600,  0.0574, -0.1371],\n",
       "                        [ 0.0576, -0.0421,  0.0680],\n",
       "                        [ 0.1054, -0.0453,  0.0161]],\n",
       "              \n",
       "                       [[ 0.1291,  0.1100,  0.0454],\n",
       "                        [-0.0073, -0.0817, -0.1311],\n",
       "                        [-0.0194,  0.1000,  0.0930]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0218, -0.0406, -0.0792],\n",
       "                        [-0.0226, -0.0787,  0.0617],\n",
       "                        [-0.1325, -0.0276,  0.0910]],\n",
       "              \n",
       "                       [[ 0.0684,  0.0901,  0.0499],\n",
       "                        [-0.0914,  0.0737,  0.1275],\n",
       "                        [ 0.1059, -0.0486,  0.0680]],\n",
       "              \n",
       "                       [[ 0.1275,  0.0956, -0.1167],\n",
       "                        [ 0.0348,  0.0274, -0.1309],\n",
       "                        [-0.0776,  0.0026, -0.0240]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1210, -0.0216,  0.0400],\n",
       "                        [-0.0872,  0.0159,  0.0118],\n",
       "                        [ 0.0640,  0.0467,  0.1286]],\n",
       "              \n",
       "                       [[-0.1080, -0.0587, -0.0233],\n",
       "                        [ 0.0815,  0.0858,  0.0862],\n",
       "                        [ 0.1058,  0.0017,  0.0539]],\n",
       "              \n",
       "                       [[-0.1048, -0.0118, -0.0111],\n",
       "                        [-0.0623,  0.0490, -0.1068],\n",
       "                        [-0.0227,  0.0450, -0.0368]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0834, -0.1127, -0.1312],\n",
       "                        [-0.1372, -0.0291, -0.0459],\n",
       "                        [-0.0218,  0.0042, -0.0080]],\n",
       "              \n",
       "                       [[ 0.1263, -0.0585, -0.0211],\n",
       "                        [ 0.0964,  0.0188, -0.0574],\n",
       "                        [ 0.1240, -0.0627, -0.0248]],\n",
       "              \n",
       "                       [[ 0.0808,  0.1340,  0.1244],\n",
       "                        [ 0.1020, -0.0088, -0.0134],\n",
       "                        [ 0.1029, -0.0861, -0.0275]]]])),\n",
       "             ('conv1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv2.weight',\n",
       "              tensor([[[[ 0.0904, -0.0738,  0.0808],\n",
       "                        [ 0.0362, -0.0523,  0.0628],\n",
       "                        [ 0.0680, -0.0293,  0.0327]],\n",
       "              \n",
       "                       [[ 0.0747,  0.0677,  0.0171],\n",
       "                        [ 0.0189,  0.0869,  0.0103],\n",
       "                        [-0.0521,  0.0224, -0.0026]],\n",
       "              \n",
       "                       [[-0.0640, -0.0889, -0.0280],\n",
       "                        [ 0.0651,  0.0105,  0.0270],\n",
       "                        [-0.0602,  0.0798, -0.0962]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0618,  0.0657, -0.0210],\n",
       "                        [ 0.0089,  0.0147,  0.0537],\n",
       "                        [ 0.0722, -0.0284,  0.0556]],\n",
       "              \n",
       "                       [[-0.0868,  0.0115, -0.0598],\n",
       "                        [-0.0127, -0.0791, -0.0690],\n",
       "                        [ 0.0811,  0.0786,  0.0406]],\n",
       "              \n",
       "                       [[-0.0118,  0.0489, -0.0351],\n",
       "                        [ 0.0503,  0.0845, -0.0831],\n",
       "                        [-0.0193,  0.0860,  0.0201]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0016, -0.0596, -0.0170],\n",
       "                        [ 0.0808,  0.0776, -0.0001],\n",
       "                        [ 0.0139,  0.0609,  0.0317]],\n",
       "              \n",
       "                       [[-0.1012,  0.0337,  0.0542],\n",
       "                        [ 0.0379, -0.0022, -0.0322],\n",
       "                        [ 0.0623, -0.0445, -0.0094]],\n",
       "              \n",
       "                       [[ 0.0585, -0.0167,  0.0879],\n",
       "                        [ 0.0691,  0.0840,  0.0086],\n",
       "                        [ 0.0134,  0.0820, -0.0212]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0734, -0.0478, -0.0140],\n",
       "                        [-0.0195,  0.0842, -0.0561],\n",
       "                        [ 0.0339, -0.0621,  0.0457]],\n",
       "              \n",
       "                       [[ 0.1020, -0.0686, -0.0256],\n",
       "                        [ 0.0160, -0.0269,  0.0888],\n",
       "                        [ 0.0441, -0.0202,  0.0420]],\n",
       "              \n",
       "                       [[ 0.0179,  0.0882, -0.0748],\n",
       "                        [ 0.0340, -0.1020, -0.0144],\n",
       "                        [-0.0475, -0.0228,  0.0407]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0696,  0.0288,  0.0809],\n",
       "                        [-0.0701,  0.0035, -0.0478],\n",
       "                        [-0.0718,  0.0595, -0.0348]],\n",
       "              \n",
       "                       [[ 0.0169, -0.0496, -0.0392],\n",
       "                        [-0.0891, -0.0845,  0.0715],\n",
       "                        [ 0.0460,  0.0009, -0.0573]],\n",
       "              \n",
       "                       [[-0.0253,  0.0710,  0.0366],\n",
       "                        [ 0.0223, -0.0073, -0.0991],\n",
       "                        [-0.0765, -0.0768,  0.0106]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0782,  0.0534,  0.0778],\n",
       "                        [-0.0423,  0.0843,  0.0287],\n",
       "                        [-0.0900,  0.0496, -0.0520]],\n",
       "              \n",
       "                       [[-0.0261,  0.0299,  0.0161],\n",
       "                        [-0.0834, -0.0784,  0.0099],\n",
       "                        [-0.0648, -0.0416, -0.0958]],\n",
       "              \n",
       "                       [[-0.0007, -0.0812,  0.0095],\n",
       "                        [ 0.0243, -0.0211, -0.0719],\n",
       "                        [ 0.0268, -0.0547, -0.0911]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0692,  0.0685, -0.0170],\n",
       "                        [-0.0834,  0.0238, -0.0816],\n",
       "                        [ 0.0441, -0.0166,  0.0110]],\n",
       "              \n",
       "                       [[ 0.0687,  0.0514,  0.0358],\n",
       "                        [ 0.0068,  0.0034, -0.0613],\n",
       "                        [ 0.0492, -0.0459,  0.0064]],\n",
       "              \n",
       "                       [[-0.0477, -0.0279,  0.0168],\n",
       "                        [-0.0851,  0.0194, -0.0499],\n",
       "                        [ 0.0843, -0.0695, -0.0343]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0338, -0.0399,  0.0008],\n",
       "                        [-0.0469,  0.0545,  0.0496],\n",
       "                        [-0.0232, -0.0054,  0.0736]],\n",
       "              \n",
       "                       [[-0.0649, -0.0840,  0.0374],\n",
       "                        [-0.0066,  0.0945,  0.0285],\n",
       "                        [ 0.0071, -0.0858, -0.0141]],\n",
       "              \n",
       "                       [[ 0.0846, -0.0895, -0.0968],\n",
       "                        [ 0.0410,  0.0186,  0.0309],\n",
       "                        [ 0.0872, -0.0354, -0.0216]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0303,  0.0655, -0.1011],\n",
       "                        [ 0.0565,  0.0553, -0.0052],\n",
       "                        [ 0.0348,  0.0251,  0.0693]],\n",
       "              \n",
       "                       [[-0.1014, -0.0349,  0.0987],\n",
       "                        [-0.0950,  0.0468, -0.0425],\n",
       "                        [ 0.0366,  0.0478,  0.0565]],\n",
       "              \n",
       "                       [[ 0.0841, -0.0987, -0.0811],\n",
       "                        [-0.0391, -0.0870, -0.0257],\n",
       "                        [ 0.0285,  0.0445,  0.0308]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0190, -0.0755, -0.0896],\n",
       "                        [-0.0681,  0.0617, -0.0467],\n",
       "                        [-0.0665,  0.0819,  0.0545]],\n",
       "              \n",
       "                       [[ 0.0940,  0.0981,  0.0788],\n",
       "                        [ 0.0706, -0.0873,  0.0054],\n",
       "                        [ 0.0464, -0.0550, -0.0977]],\n",
       "              \n",
       "                       [[ 0.0782,  0.0036,  0.1008],\n",
       "                        [ 0.0710,  0.0252,  0.0866],\n",
       "                        [-0.1017, -0.0534, -0.0979]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0805, -0.0381,  0.0075],\n",
       "                        [ 0.0445,  0.0639,  0.0526],\n",
       "                        [-0.0198,  0.0177, -0.0172]],\n",
       "              \n",
       "                       [[ 0.0417,  0.0450,  0.0618],\n",
       "                        [-0.0876, -0.0875,  0.0483],\n",
       "                        [ 0.0275, -0.0061, -0.0193]],\n",
       "              \n",
       "                       [[-0.0971, -0.1004,  0.0567],\n",
       "                        [ 0.0329,  0.0935,  0.0205],\n",
       "                        [-0.0569, -0.0843,  0.0185]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0263,  0.0507,  0.0523],\n",
       "                        [ 0.0190,  0.0394,  0.1016],\n",
       "                        [ 0.0159, -0.0656,  0.0861]],\n",
       "              \n",
       "                       [[-0.0473,  0.0817, -0.0454],\n",
       "                        [ 0.0457,  0.0308, -0.0448],\n",
       "                        [-0.0354,  0.0795,  0.0588]],\n",
       "              \n",
       "                       [[-0.0070, -0.0975, -0.0361],\n",
       "                        [ 0.0279,  0.0682, -0.0920],\n",
       "                        [-0.0879, -0.0010, -0.0984]]]])),\n",
       "             ('conv2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv3.weight',\n",
       "              tensor([[[[ 8.1554e-02, -7.8051e-02,  6.0935e-02],\n",
       "                        [-1.3507e-02, -2.4329e-02,  9.6390e-03],\n",
       "                        [ 4.3930e-02,  5.9522e-02,  7.7850e-02]],\n",
       "              \n",
       "                       [[-4.8301e-02, -7.6628e-02, -6.4131e-03],\n",
       "                        [ 4.6157e-02, -5.9651e-02,  3.9767e-02],\n",
       "                        [ 5.3270e-02, -3.9843e-02, -3.7277e-02]],\n",
       "              \n",
       "                       [[-3.3389e-02, -5.6154e-02,  2.4818e-02],\n",
       "                        [ 3.0111e-02,  4.6894e-02,  2.6186e-02],\n",
       "                        [-6.0589e-02,  2.7293e-02,  7.8213e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.6078e-02,  6.8248e-02,  1.2343e-02],\n",
       "                        [ 6.4196e-02, -5.7073e-02,  6.6453e-02],\n",
       "                        [-7.2663e-02, -4.2503e-02, -8.1474e-02]],\n",
       "              \n",
       "                       [[ 3.8898e-02,  8.1033e-03,  6.6392e-02],\n",
       "                        [ 7.6875e-02, -2.4706e-02,  5.3559e-02],\n",
       "                        [-4.1131e-02, -4.3139e-03, -5.1531e-02]],\n",
       "              \n",
       "                       [[-7.3281e-02,  9.2280e-03, -2.0363e-03],\n",
       "                        [-5.6611e-02,  7.9838e-02,  6.4352e-02],\n",
       "                        [-7.5030e-02, -2.2302e-02, -5.2159e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8992e-02,  7.3438e-02,  6.3258e-02],\n",
       "                        [-6.6058e-02,  7.7293e-02, -6.3918e-02],\n",
       "                        [ 4.6181e-02,  1.5707e-02, -2.7207e-02]],\n",
       "              \n",
       "                       [[-6.6154e-02, -7.7172e-02,  5.9887e-03],\n",
       "                        [ 8.9488e-03,  1.7488e-02,  1.9967e-02],\n",
       "                        [ 3.7282e-02, -2.2025e-02,  2.6331e-03]],\n",
       "              \n",
       "                       [[ 5.6491e-02, -7.3632e-02, -2.9423e-02],\n",
       "                        [ 5.1404e-02, -7.3823e-02, -6.7568e-02],\n",
       "                        [ 6.6079e-02, -3.7915e-02, -1.5044e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.8109e-03,  4.8257e-03, -2.1920e-02],\n",
       "                        [ 3.9909e-03, -7.3187e-02,  5.8924e-02],\n",
       "                        [-5.1494e-02,  3.0063e-02, -7.8276e-02]],\n",
       "              \n",
       "                       [[ 4.3970e-02,  3.0502e-03, -6.1191e-02],\n",
       "                        [ 6.3117e-02, -4.4589e-02,  7.0548e-02],\n",
       "                        [ 6.5843e-02, -1.4465e-02, -6.4748e-02]],\n",
       "              \n",
       "                       [[-5.0290e-03, -5.3362e-02,  3.6842e-03],\n",
       "                        [ 5.7439e-02,  2.0638e-02,  2.4605e-02],\n",
       "                        [ 1.1842e-02, -6.6718e-02, -4.3477e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.3805e-02,  2.1773e-02, -2.3562e-02],\n",
       "                        [-2.7871e-02, -6.8353e-02,  6.6618e-02],\n",
       "                        [-2.6993e-04, -8.0767e-02,  7.6941e-02]],\n",
       "              \n",
       "                       [[ 2.1687e-02, -2.8467e-02, -7.3101e-02],\n",
       "                        [ 5.1528e-02, -5.7722e-02,  7.0320e-02],\n",
       "                        [ 1.2966e-02, -6.8144e-02, -4.0188e-02]],\n",
       "              \n",
       "                       [[-3.3503e-02, -2.0140e-02,  1.9858e-02],\n",
       "                        [-8.0107e-02, -6.4641e-02,  5.6102e-02],\n",
       "                        [ 2.5225e-02,  1.7529e-02, -5.1193e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4271e-03, -7.5548e-02, -5.9011e-04],\n",
       "                        [-5.1500e-02,  2.9185e-02,  6.8789e-02],\n",
       "                        [ 3.3308e-02, -2.3407e-02, -5.3050e-02]],\n",
       "              \n",
       "                       [[-7.4022e-02, -8.1399e-02, -6.4205e-02],\n",
       "                        [-6.9522e-02, -4.8864e-02,  7.4363e-02],\n",
       "                        [ 7.5511e-02, -6.3115e-02, -4.1817e-02]],\n",
       "              \n",
       "                       [[ 7.1694e-02,  5.6294e-02,  2.6185e-02],\n",
       "                        [ 1.7031e-02, -2.4845e-02, -5.2250e-02],\n",
       "                        [-4.8137e-02,  3.9109e-02,  6.3158e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2032e-02, -3.5909e-02, -1.7904e-02],\n",
       "                        [-1.5473e-02,  3.9891e-02, -1.4975e-02],\n",
       "                        [-8.0492e-03,  5.0089e-02, -3.3316e-02]],\n",
       "              \n",
       "                       [[ 5.0320e-02, -7.2398e-02, -6.9301e-02],\n",
       "                        [ 8.5409e-03, -4.0847e-02, -8.0823e-02],\n",
       "                        [ 4.0771e-02,  7.1986e-03,  4.6459e-02]],\n",
       "              \n",
       "                       [[-3.8610e-02,  1.1487e-02,  7.5289e-02],\n",
       "                        [ 2.9885e-02, -1.2207e-02, -7.2001e-02],\n",
       "                        [-2.9089e-02,  6.6364e-02,  6.5084e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.5023e-02, -1.9285e-02, -1.0003e-02],\n",
       "                        [ 7.5913e-03, -7.4458e-02, -5.7987e-02],\n",
       "                        [-6.1517e-02, -4.1256e-02, -1.3855e-03]],\n",
       "              \n",
       "                       [[-4.2867e-02,  1.7522e-02, -4.7894e-02],\n",
       "                        [ 5.5461e-02,  4.3187e-02,  1.5955e-02],\n",
       "                        [ 3.4701e-02, -5.7518e-02,  7.6708e-02]],\n",
       "              \n",
       "                       [[-1.0699e-02,  5.9967e-02, -6.9040e-02],\n",
       "                        [ 4.3467e-02, -7.1819e-02, -1.8675e-02],\n",
       "                        [ 7.6498e-02, -3.3707e-02,  1.6987e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4195e-02,  7.6936e-02,  7.4380e-03],\n",
       "                        [-6.3992e-02, -2.6832e-02, -6.8319e-03],\n",
       "                        [-1.6464e-02,  1.2367e-02, -5.2291e-03]],\n",
       "              \n",
       "                       [[-7.2094e-02,  6.1441e-02, -4.0880e-02],\n",
       "                        [-3.1603e-02, -1.4933e-02, -6.1731e-02],\n",
       "                        [ 7.5546e-02,  7.7250e-02, -5.3686e-02]],\n",
       "              \n",
       "                       [[-1.2220e-02, -7.4262e-02,  3.4716e-02],\n",
       "                        [ 2.4766e-05, -4.1923e-02,  2.6024e-02],\n",
       "                        [-4.4213e-02,  5.6881e-02, -3.9744e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.0149e-03, -6.8073e-02, -5.7840e-02],\n",
       "                        [ 2.6222e-02, -6.8783e-02, -7.9409e-02],\n",
       "                        [-2.6179e-02, -2.6524e-02, -4.1062e-03]],\n",
       "              \n",
       "                       [[ 2.0283e-02,  7.2244e-03,  2.0990e-02],\n",
       "                        [-1.5937e-02, -4.6584e-02,  1.2118e-02],\n",
       "                        [ 7.3487e-02,  5.6407e-02, -5.5289e-02]],\n",
       "              \n",
       "                       [[-1.8202e-02,  2.5072e-02, -8.1314e-02],\n",
       "                        [-8.1452e-02,  3.2860e-02, -2.8624e-02],\n",
       "                        [-7.7368e-02,  3.3256e-02,  4.6935e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1048e-02, -5.0853e-02,  3.8035e-02],\n",
       "                        [-5.1988e-02,  6.9351e-02, -3.2974e-02],\n",
       "                        [ 1.3319e-02,  5.1167e-03, -5.6618e-04]],\n",
       "              \n",
       "                       [[ 4.2061e-02, -7.5083e-02, -4.8009e-02],\n",
       "                        [-6.6191e-02,  2.2691e-02,  1.7207e-02],\n",
       "                        [-8.1069e-02,  1.9081e-02,  8.2341e-02]],\n",
       "              \n",
       "                       [[-6.7233e-03, -8.1769e-02,  1.9007e-02],\n",
       "                        [-6.5549e-02, -5.0602e-02, -7.7903e-02],\n",
       "                        [ 1.7873e-02, -6.0487e-02, -6.3341e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.2738e-02, -6.3756e-02, -1.6736e-02],\n",
       "                        [ 3.6007e-02,  7.3904e-02, -3.0809e-02],\n",
       "                        [-5.6996e-02,  4.4563e-02, -8.1434e-02]],\n",
       "              \n",
       "                       [[-6.2872e-02, -5.6842e-02, -1.8486e-04],\n",
       "                        [-4.2392e-02,  1.2658e-02,  1.6104e-02],\n",
       "                        [-7.4319e-02, -2.3404e-02, -7.5487e-02]],\n",
       "              \n",
       "                       [[ 7.8748e-02,  5.2883e-02,  2.7595e-02],\n",
       "                        [ 4.5379e-02, -1.3384e-02, -4.0719e-02],\n",
       "                        [-2.6653e-02, -3.5580e-02,  1.9653e-02]]]])),\n",
       "             ('conv3.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv4.weight',\n",
       "              tensor([[[[-0.0622, -0.0417, -0.0612],\n",
       "                        [ 0.0212,  0.0012, -0.0700],\n",
       "                        [ 0.0324,  0.0584, -0.0258]],\n",
       "              \n",
       "                       [[-0.0217, -0.0673, -0.0621],\n",
       "                        [ 0.0369,  0.0144,  0.0550],\n",
       "                        [ 0.0372,  0.0043,  0.0608]],\n",
       "              \n",
       "                       [[ 0.0561,  0.0472, -0.0347],\n",
       "                        [-0.0531,  0.0145, -0.0533],\n",
       "                        [ 0.0106, -0.0026,  0.0587]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0295,  0.0194,  0.0423],\n",
       "                        [-0.0599,  0.0001,  0.0251],\n",
       "                        [ 0.0120,  0.0232, -0.0657]],\n",
       "              \n",
       "                       [[ 0.0433, -0.0117,  0.0657],\n",
       "                        [-0.0563, -0.0266,  0.0412],\n",
       "                        [-0.0694,  0.0701, -0.0521]],\n",
       "              \n",
       "                       [[ 0.0073, -0.0442, -0.0115],\n",
       "                        [-0.0482, -0.0033, -0.0507],\n",
       "                        [ 0.0214, -0.0192, -0.0201]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0234, -0.0431, -0.0635],\n",
       "                        [ 0.0186,  0.0559, -0.0344],\n",
       "                        [ 0.0374, -0.0039, -0.0388]],\n",
       "              \n",
       "                       [[-0.0231,  0.0258,  0.0156],\n",
       "                        [ 0.0444,  0.0081,  0.0056],\n",
       "                        [ 0.0336, -0.0112, -0.0472]],\n",
       "              \n",
       "                       [[-0.0107,  0.0661, -0.0252],\n",
       "                        [-0.0345,  0.0086,  0.0082],\n",
       "                        [-0.0110, -0.0256, -0.0210]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0524, -0.0127, -0.0463],\n",
       "                        [-0.0295, -0.0055,  0.0459],\n",
       "                        [ 0.0599, -0.0570,  0.0654]],\n",
       "              \n",
       "                       [[-0.0310,  0.0496,  0.0037],\n",
       "                        [-0.0078, -0.0357, -0.0420],\n",
       "                        [ 0.0057, -0.0253,  0.0019]],\n",
       "              \n",
       "                       [[-0.0242, -0.0397, -0.0709],\n",
       "                        [-0.0452,  0.0090, -0.0012],\n",
       "                        [ 0.0425, -0.0021,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0342,  0.0435, -0.0247],\n",
       "                        [ 0.0194,  0.0082, -0.0394],\n",
       "                        [-0.0240,  0.0669, -0.0200]],\n",
       "              \n",
       "                       [[-0.0432, -0.0681,  0.0637],\n",
       "                        [ 0.0235, -0.0428, -0.0221],\n",
       "                        [ 0.0487, -0.0704,  0.0033]],\n",
       "              \n",
       "                       [[ 0.0227,  0.0125, -0.0073],\n",
       "                        [-0.0675,  0.0162, -0.0507],\n",
       "                        [ 0.0441, -0.0549, -0.0079]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0234,  0.0224,  0.0054],\n",
       "                        [ 0.0160,  0.0063, -0.0477],\n",
       "                        [-0.0563,  0.0502, -0.0488]],\n",
       "              \n",
       "                       [[ 0.0104,  0.0625,  0.0090],\n",
       "                        [-0.0662,  0.0470, -0.0473],\n",
       "                        [-0.0476, -0.0548, -0.0138]],\n",
       "              \n",
       "                       [[-0.0577,  0.0563,  0.0228],\n",
       "                        [ 0.0259,  0.0566, -0.0433],\n",
       "                        [ 0.0561,  0.0492,  0.0305]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0153, -0.0239,  0.0453],\n",
       "                        [ 0.0600,  0.0720,  0.0597],\n",
       "                        [-0.0214, -0.0546, -0.0102]],\n",
       "              \n",
       "                       [[ 0.0083, -0.0660,  0.0463],\n",
       "                        [-0.0427,  0.0309, -0.0206],\n",
       "                        [ 0.0344,  0.0021, -0.0196]],\n",
       "              \n",
       "                       [[ 0.0099,  0.0272,  0.0231],\n",
       "                        [ 0.0204,  0.0072, -0.0262],\n",
       "                        [-0.0644,  0.0465, -0.0029]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0527, -0.0659,  0.0395],\n",
       "                        [ 0.0142, -0.0071, -0.0706],\n",
       "                        [-0.0658, -0.0083,  0.0697]],\n",
       "              \n",
       "                       [[ 0.0217,  0.0434,  0.0304],\n",
       "                        [-0.0523, -0.0372, -0.0091],\n",
       "                        [-0.0398, -0.0138,  0.0182]],\n",
       "              \n",
       "                       [[-0.0007,  0.0503, -0.0138],\n",
       "                        [ 0.0096, -0.0591, -0.0149],\n",
       "                        [ 0.0301, -0.0198, -0.0700]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0639,  0.0228, -0.0608],\n",
       "                        [ 0.0594, -0.0317,  0.0559],\n",
       "                        [ 0.0346,  0.0075,  0.0131]],\n",
       "              \n",
       "                       [[ 0.0389,  0.0147,  0.0153],\n",
       "                        [ 0.0303, -0.0059, -0.0135],\n",
       "                        [-0.0408,  0.0604,  0.0362]],\n",
       "              \n",
       "                       [[-0.0697, -0.0577, -0.0047],\n",
       "                        [-0.0614,  0.0090,  0.0608],\n",
       "                        [-0.0404,  0.0235,  0.0222]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0385,  0.0107,  0.0319],\n",
       "                        [-0.0206, -0.0019, -0.0312],\n",
       "                        [-0.0660, -0.0326,  0.0093]],\n",
       "              \n",
       "                       [[-0.0014, -0.0467, -0.0406],\n",
       "                        [ 0.0317,  0.0294, -0.0140],\n",
       "                        [-0.0567, -0.0459,  0.0312]],\n",
       "              \n",
       "                       [[ 0.0035, -0.0576,  0.0322],\n",
       "                        [-0.0517, -0.0480,  0.0460],\n",
       "                        [-0.0264, -0.0705, -0.0174]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0221,  0.0242,  0.0710],\n",
       "                        [-0.0259, -0.0502,  0.0364],\n",
       "                        [-0.0442, -0.0285,  0.0635]],\n",
       "              \n",
       "                       [[ 0.0343,  0.0564,  0.0661],\n",
       "                        [-0.0156, -0.0381,  0.0526],\n",
       "                        [ 0.0644,  0.0166,  0.0160]],\n",
       "              \n",
       "                       [[-0.0471,  0.0029,  0.0512],\n",
       "                        [-0.0384,  0.0381,  0.0372],\n",
       "                        [-0.0337,  0.0079,  0.0258]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0500, -0.0692, -0.0340],\n",
       "                        [-0.0620,  0.0476, -0.0421],\n",
       "                        [-0.0471,  0.0629, -0.0171]],\n",
       "              \n",
       "                       [[ 0.0105,  0.0365, -0.0610],\n",
       "                        [ 0.0093, -0.0113, -0.0196],\n",
       "                        [-0.0345,  0.0372, -0.0547]],\n",
       "              \n",
       "                       [[-0.0553, -0.0078, -0.0505],\n",
       "                        [-0.0377,  0.0428,  0.0675],\n",
       "                        [ 0.0710, -0.0217, -0.0001]]]])),\n",
       "             ('conv4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv5.weight',\n",
       "              tensor([[[[-0.0380, -0.0449, -0.0013],\n",
       "                        [ 0.0417,  0.0073, -0.0185],\n",
       "                        [ 0.0050,  0.0096,  0.0390]],\n",
       "              \n",
       "                       [[-0.0398,  0.0158,  0.0158],\n",
       "                        [-0.0262,  0.0559,  0.0040],\n",
       "                        [ 0.0451, -0.0018,  0.0067]],\n",
       "              \n",
       "                       [[ 0.0045, -0.0270, -0.0324],\n",
       "                        [ 0.0027, -0.0542,  0.0426],\n",
       "                        [-0.0483,  0.0205, -0.0024]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0465,  0.0403,  0.0176],\n",
       "                        [ 0.0229, -0.0019,  0.0014],\n",
       "                        [ 0.0047,  0.0523, -0.0015]],\n",
       "              \n",
       "                       [[-0.0373, -0.0321,  0.0477],\n",
       "                        [ 0.0098,  0.0174, -0.0123],\n",
       "                        [-0.0247, -0.0444,  0.0542]],\n",
       "              \n",
       "                       [[-0.0280, -0.0504, -0.0003],\n",
       "                        [ 0.0194,  0.0435, -0.0481],\n",
       "                        [-0.0329, -0.0147,  0.0063]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0516, -0.0038, -0.0006],\n",
       "                        [-0.0484,  0.0185,  0.0558],\n",
       "                        [ 0.0429,  0.0197,  0.0288]],\n",
       "              \n",
       "                       [[ 0.0008, -0.0467,  0.0295],\n",
       "                        [ 0.0013, -0.0005,  0.0398],\n",
       "                        [ 0.0107, -0.0513, -0.0351]],\n",
       "              \n",
       "                       [[ 0.0559,  0.0244, -0.0133],\n",
       "                        [-0.0490, -0.0171,  0.0006],\n",
       "                        [-0.0539, -0.0341, -0.0542]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0106,  0.0300,  0.0072],\n",
       "                        [-0.0395,  0.0239,  0.0010],\n",
       "                        [-0.0435,  0.0505, -0.0316]],\n",
       "              \n",
       "                       [[-0.0102,  0.0365,  0.0091],\n",
       "                        [-0.0578,  0.0285,  0.0451],\n",
       "                        [-0.0586,  0.0162, -0.0279]],\n",
       "              \n",
       "                       [[ 0.0111, -0.0239,  0.0283],\n",
       "                        [ 0.0380,  0.0391,  0.0373],\n",
       "                        [ 0.0529, -0.0517, -0.0218]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0119,  0.0286, -0.0471],\n",
       "                        [-0.0150,  0.0496,  0.0520],\n",
       "                        [ 0.0091,  0.0124, -0.0087]],\n",
       "              \n",
       "                       [[ 0.0065,  0.0430,  0.0370],\n",
       "                        [ 0.0114,  0.0342, -0.0063],\n",
       "                        [-0.0293, -0.0315, -0.0351]],\n",
       "              \n",
       "                       [[-0.0091,  0.0086, -0.0005],\n",
       "                        [ 0.0589,  0.0158, -0.0117],\n",
       "                        [-0.0423,  0.0175, -0.0475]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0510,  0.0066, -0.0063],\n",
       "                        [ 0.0049, -0.0182,  0.0384],\n",
       "                        [ 0.0525,  0.0548,  0.0376]],\n",
       "              \n",
       "                       [[ 0.0233,  0.0273,  0.0220],\n",
       "                        [ 0.0236,  0.0253, -0.0308],\n",
       "                        [-0.0457, -0.0479,  0.0478]],\n",
       "              \n",
       "                       [[ 0.0144, -0.0042,  0.0016],\n",
       "                        [ 0.0513,  0.0086,  0.0268],\n",
       "                        [-0.0541, -0.0456, -0.0450]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0274, -0.0541, -0.0058],\n",
       "                        [-0.0070,  0.0197,  0.0287],\n",
       "                        [ 0.0185, -0.0351, -0.0391]],\n",
       "              \n",
       "                       [[-0.0432,  0.0059,  0.0170],\n",
       "                        [-0.0160,  0.0316,  0.0321],\n",
       "                        [ 0.0239,  0.0134,  0.0100]],\n",
       "              \n",
       "                       [[-0.0244,  0.0256,  0.0015],\n",
       "                        [-0.0151, -0.0383, -0.0366],\n",
       "                        [ 0.0259,  0.0413,  0.0166]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0040,  0.0396, -0.0180],\n",
       "                        [ 0.0403,  0.0564,  0.0579],\n",
       "                        [ 0.0125, -0.0532,  0.0377]],\n",
       "              \n",
       "                       [[ 0.0427, -0.0322,  0.0512],\n",
       "                        [-0.0230, -0.0451,  0.0034],\n",
       "                        [-0.0356,  0.0365,  0.0547]],\n",
       "              \n",
       "                       [[ 0.0051, -0.0543, -0.0304],\n",
       "                        [-0.0288, -0.0252, -0.0087],\n",
       "                        [-0.0106, -0.0115,  0.0099]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0472,  0.0403, -0.0490],\n",
       "                        [-0.0217, -0.0454,  0.0463],\n",
       "                        [-0.0461,  0.0341,  0.0267]],\n",
       "              \n",
       "                       [[-0.0272,  0.0434,  0.0587],\n",
       "                        [ 0.0039, -0.0360,  0.0562],\n",
       "                        [ 0.0122,  0.0326,  0.0273]],\n",
       "              \n",
       "                       [[ 0.0091,  0.0333, -0.0129],\n",
       "                        [ 0.0247,  0.0162, -0.0164],\n",
       "                        [-0.0186, -0.0485,  0.0287]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0230,  0.0231,  0.0305],\n",
       "                        [-0.0354,  0.0116, -0.0556],\n",
       "                        [ 0.0481,  0.0053, -0.0085]],\n",
       "              \n",
       "                       [[-0.0418, -0.0213, -0.0346],\n",
       "                        [ 0.0220,  0.0343, -0.0476],\n",
       "                        [-0.0023,  0.0151, -0.0583]],\n",
       "              \n",
       "                       [[ 0.0136, -0.0266, -0.0330],\n",
       "                        [-0.0261,  0.0520, -0.0247],\n",
       "                        [-0.0350,  0.0248,  0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0331, -0.0068,  0.0032],\n",
       "                        [-0.0537,  0.0454, -0.0280],\n",
       "                        [-0.0051,  0.0427,  0.0015]],\n",
       "              \n",
       "                       [[ 0.0494, -0.0307,  0.0432],\n",
       "                        [ 0.0191,  0.0258,  0.0109],\n",
       "                        [ 0.0308,  0.0579,  0.0560]],\n",
       "              \n",
       "                       [[-0.0364, -0.0272,  0.0001],\n",
       "                        [-0.0576,  0.0430, -0.0286],\n",
       "                        [-0.0256, -0.0574, -0.0153]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0311,  0.0337, -0.0054],\n",
       "                        [ 0.0417,  0.0048,  0.0297],\n",
       "                        [-0.0509, -0.0335, -0.0150]],\n",
       "              \n",
       "                       [[ 0.0544, -0.0580,  0.0084],\n",
       "                        [-0.0399, -0.0504, -0.0363],\n",
       "                        [-0.0073,  0.0361, -0.0522]],\n",
       "              \n",
       "                       [[ 0.0013,  0.0270,  0.0373],\n",
       "                        [ 0.0459,  0.0403,  0.0231],\n",
       "                        [-0.0181,  0.0289,  0.0305]]]])),\n",
       "             ('conv5.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('conv6.weight',\n",
       "              tensor([[[[-0.0101,  0.0341, -0.0496],\n",
       "                        [-0.0314, -0.0401,  0.0223],\n",
       "                        [-0.0464,  0.0026,  0.0422]],\n",
       "              \n",
       "                       [[-0.0466,  0.0360, -0.0254],\n",
       "                        [ 0.0211, -0.0177, -0.0211],\n",
       "                        [-0.0328, -0.0340, -0.0376]],\n",
       "              \n",
       "                       [[-0.0112, -0.0324, -0.0288],\n",
       "                        [ 0.0036, -0.0144, -0.0466],\n",
       "                        [ 0.0297, -0.0328, -0.0134]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0266,  0.0234, -0.0455],\n",
       "                        [-0.0350,  0.0310,  0.0034],\n",
       "                        [ 0.0463,  0.0347,  0.0478]],\n",
       "              \n",
       "                       [[ 0.0108,  0.0333, -0.0390],\n",
       "                        [ 0.0184, -0.0407,  0.0264],\n",
       "                        [ 0.0493, -0.0089,  0.0365]],\n",
       "              \n",
       "                       [[-0.0209, -0.0490, -0.0264],\n",
       "                        [-0.0003, -0.0435,  0.0290],\n",
       "                        [-0.0114,  0.0418, -0.0445]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0096,  0.0265, -0.0265],\n",
       "                        [-0.0018, -0.0215, -0.0493],\n",
       "                        [-0.0255, -0.0009,  0.0295]],\n",
       "              \n",
       "                       [[ 0.0052,  0.0061,  0.0203],\n",
       "                        [ 0.0222,  0.0016,  0.0220],\n",
       "                        [-0.0256,  0.0180, -0.0218]],\n",
       "              \n",
       "                       [[ 0.0005,  0.0365,  0.0277],\n",
       "                        [ 0.0081,  0.0096,  0.0506],\n",
       "                        [-0.0481, -0.0372, -0.0230]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0047,  0.0146,  0.0432],\n",
       "                        [ 0.0165, -0.0461, -0.0298],\n",
       "                        [-0.0220,  0.0224, -0.0003]],\n",
       "              \n",
       "                       [[-0.0038, -0.0196,  0.0200],\n",
       "                        [-0.0428,  0.0232,  0.0489],\n",
       "                        [-0.0176,  0.0482,  0.0279]],\n",
       "              \n",
       "                       [[-0.0184,  0.0046, -0.0150],\n",
       "                        [ 0.0011, -0.0426, -0.0345],\n",
       "                        [-0.0156,  0.0085,  0.0402]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0463, -0.0335,  0.0441],\n",
       "                        [-0.0474,  0.0308, -0.0333],\n",
       "                        [-0.0097,  0.0044,  0.0168]],\n",
       "              \n",
       "                       [[-0.0390,  0.0105,  0.0186],\n",
       "                        [ 0.0274, -0.0022,  0.0502],\n",
       "                        [ 0.0219,  0.0129,  0.0501]],\n",
       "              \n",
       "                       [[ 0.0330, -0.0044, -0.0491],\n",
       "                        [-0.0431, -0.0143, -0.0365],\n",
       "                        [ 0.0157,  0.0274, -0.0235]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0205, -0.0493, -0.0228],\n",
       "                        [-0.0480, -0.0350,  0.0506],\n",
       "                        [-0.0070,  0.0012,  0.0441]],\n",
       "              \n",
       "                       [[-0.0276, -0.0341, -0.0262],\n",
       "                        [-0.0439,  0.0469, -0.0248],\n",
       "                        [-0.0013, -0.0472,  0.0352]],\n",
       "              \n",
       "                       [[-0.0234, -0.0267, -0.0037],\n",
       "                        [ 0.0384, -0.0330, -0.0092],\n",
       "                        [ 0.0013,  0.0239,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0019, -0.0420,  0.0319],\n",
       "                        [ 0.0269, -0.0096, -0.0143],\n",
       "                        [-0.0352,  0.0498, -0.0212]],\n",
       "              \n",
       "                       [[-0.0134,  0.0066,  0.0005],\n",
       "                        [-0.0322,  0.0036, -0.0464],\n",
       "                        [-0.0100, -0.0433,  0.0472]],\n",
       "              \n",
       "                       [[-0.0095,  0.0466,  0.0195],\n",
       "                        [ 0.0302, -0.0469, -0.0339],\n",
       "                        [ 0.0253, -0.0325,  0.0096]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0037, -0.0394, -0.0356],\n",
       "                        [-0.0508, -0.0167,  0.0159],\n",
       "                        [ 0.0055, -0.0098,  0.0085]],\n",
       "              \n",
       "                       [[-0.0022, -0.0149,  0.0233],\n",
       "                        [-0.0036,  0.0201,  0.0030],\n",
       "                        [ 0.0239, -0.0466,  0.0209]],\n",
       "              \n",
       "                       [[-0.0140, -0.0417, -0.0331],\n",
       "                        [ 0.0432,  0.0288,  0.0485],\n",
       "                        [ 0.0316,  0.0278,  0.0197]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0437, -0.0214,  0.0246],\n",
       "                        [ 0.0021, -0.0155, -0.0281],\n",
       "                        [ 0.0044,  0.0392,  0.0263]],\n",
       "              \n",
       "                       [[ 0.0444,  0.0188,  0.0296],\n",
       "                        [-0.0345, -0.0393,  0.0493],\n",
       "                        [ 0.0079, -0.0167, -0.0060]],\n",
       "              \n",
       "                       [[ 0.0371, -0.0393, -0.0239],\n",
       "                        [-0.0048, -0.0022,  0.0107],\n",
       "                        [ 0.0450, -0.0322, -0.0245]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0504,  0.0011, -0.0003],\n",
       "                        [-0.0006,  0.0132,  0.0234],\n",
       "                        [-0.0329, -0.0316, -0.0502]],\n",
       "              \n",
       "                       [[ 0.0489, -0.0020,  0.0220],\n",
       "                        [ 0.0214,  0.0473,  0.0495],\n",
       "                        [ 0.0509,  0.0048,  0.0222]],\n",
       "              \n",
       "                       [[ 0.0351,  0.0163,  0.0161],\n",
       "                        [-0.0406, -0.0422, -0.0258],\n",
       "                        [ 0.0004,  0.0328,  0.0331]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0256,  0.0332, -0.0057],\n",
       "                        [ 0.0403,  0.0311, -0.0390],\n",
       "                        [ 0.0182, -0.0091,  0.0163]],\n",
       "              \n",
       "                       [[ 0.0430,  0.0342, -0.0206],\n",
       "                        [ 0.0382,  0.0126, -0.0318],\n",
       "                        [-0.0054,  0.0239, -0.0118]],\n",
       "              \n",
       "                       [[-0.0362, -0.0492, -0.0272],\n",
       "                        [ 0.0267,  0.0479,  0.0241],\n",
       "                        [ 0.0374, -0.0022, -0.0019]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0280, -0.0265,  0.0331],\n",
       "                        [ 0.0290, -0.0483, -0.0006],\n",
       "                        [ 0.0491,  0.0441, -0.0443]],\n",
       "              \n",
       "                       [[-0.0088,  0.0473, -0.0341],\n",
       "                        [-0.0084,  0.0247,  0.0472],\n",
       "                        [-0.0294,  0.0314, -0.0108]],\n",
       "              \n",
       "                       [[-0.0336,  0.0062,  0.0394],\n",
       "                        [ 0.0320, -0.0202,  0.0139],\n",
       "                        [ 0.0403,  0.0195, -0.0316]]]])),\n",
       "             ('conv6.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[-0.0108,  0.0040,  0.0081,  ..., -0.0043, -0.0033, -0.0011],\n",
       "                      [-0.0095, -0.0100,  0.0112,  ..., -0.0023,  0.0009, -0.0099],\n",
       "                      [ 0.0133, -0.0098,  0.0037,  ...,  0.0047, -0.0134, -0.0130],\n",
       "                      ...,\n",
       "                      [-0.0102, -0.0015,  0.0087,  ..., -0.0006,  0.0081, -0.0121],\n",
       "                      [-0.0076, -0.0121, -0.0091,  ...,  0.0118, -0.0042,  0.0103],\n",
       "                      [-0.0109,  0.0134, -0.0043,  ...,  0.0102,  0.0105, -0.0011]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.1024,  0.1491,  0.0045,  ...,  0.0760, -0.1198,  0.1228],\n",
       "                      [-0.0114, -0.0295, -0.0722,  ..., -0.0176,  0.0217,  0.0967],\n",
       "                      [ 0.0857, -0.0900, -0.0634,  ...,  0.0407,  0.1036, -0.0292],\n",
       "                      ...,\n",
       "                      [ 0.1342,  0.0450,  0.0419,  ..., -0.0030, -0.0032, -0.0765],\n",
       "                      [-0.1006, -0.0974, -0.0761,  ..., -0.1422, -0.0015, -0.0766],\n",
       "                      [ 0.0164, -0.0229,  0.0025,  ..., -0.0098,  0.1041, -0.0835]])),\n",
       "             ('fc2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置交叉熵损失函数，SGD优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:40.023837Z",
     "start_time": "2025-06-26T01:43:40.019952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数，适用于多分类问题，里边会做softmax，还有会把0-9标签转换成one-hot编码\n",
    "\n",
    "print(\"损失函数:\", loss_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:40.035848Z",
     "start_time": "2025-06-26T01:43:40.032419Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD优化器，学习率为0.01，动量为0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.732814Z",
     "start_time": "2025-06-26T01:43:40.035848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df45cb3ebfab4c54bca0d56e81a7171c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/1750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "model = model.to(device) #将模型移动到GPU\n",
    "early_stopping=EarlyStopping(patience=5, delta=0.001)\n",
    "model_saver=ModelSaver(save_dir='model_weights', save_best_only=True)\n",
    "\n",
    "\n",
    "model, history = train_classification_model(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=50, early_stopping=early_stopping, model_saver=model_saver, tensorboard_logger=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.737721Z",
     "start_time": "2025-06-26T01:45:37.732814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.00016087341646198183, 'acc': 100.0, 'step': 1650},\n",
       " {'loss': 0.00012376262748148292, 'acc': 100.0, 'step': 1651},\n",
       " {'loss': 0.00027858492103405297, 'acc': 100.0, 'step': 1652},\n",
       " {'loss': 7.733277743682265e-05, 'acc': 100.0, 'step': 1653},\n",
       " {'loss': 0.00014629312499891967, 'acc': 100.0, 'step': 1654},\n",
       " {'loss': 5.877193689229898e-05, 'acc': 100.0, 'step': 1655},\n",
       " {'loss': 0.00010482493962626904, 'acc': 100.0, 'step': 1656},\n",
       " {'loss': 9.87551175057888e-05, 'acc': 100.0, 'step': 1657},\n",
       " {'loss': 0.00013876632147002965, 'acc': 100.0, 'step': 1658},\n",
       " {'loss': 0.00016856692673172802, 'acc': 100.0, 'step': 1659},\n",
       " {'loss': 0.0002506825258024037, 'acc': 100.0, 'step': 1660},\n",
       " {'loss': 0.00015049093053676188, 'acc': 100.0, 'step': 1661},\n",
       " {'loss': 0.00032546473084948957, 'acc': 100.0, 'step': 1662},\n",
       " {'loss': 0.00016565967234782875, 'acc': 100.0, 'step': 1663},\n",
       " {'loss': 0.00013308787310961634, 'acc': 100.0, 'step': 1664},\n",
       " {'loss': 0.000119059368444141, 'acc': 100.0, 'step': 1665},\n",
       " {'loss': 0.00013528182171285152, 'acc': 100.0, 'step': 1666},\n",
       " {'loss': 0.0002477796224411577, 'acc': 100.0, 'step': 1667},\n",
       " {'loss': 0.0001565424754517153, 'acc': 100.0, 'step': 1668},\n",
       " {'loss': 0.00024071345978882164, 'acc': 100.0, 'step': 1669},\n",
       " {'loss': 0.00027749573928304017, 'acc': 100.0, 'step': 1670},\n",
       " {'loss': 0.00011111413186881691, 'acc': 100.0, 'step': 1671},\n",
       " {'loss': 0.0001083562383428216, 'acc': 100.0, 'step': 1672},\n",
       " {'loss': 0.00012915725528728217, 'acc': 100.0, 'step': 1673},\n",
       " {'loss': 0.00011019494559150189, 'acc': 100.0, 'step': 1674},\n",
       " {'loss': 7.441148045472801e-05, 'acc': 100.0, 'step': 1675},\n",
       " {'loss': 0.00021465109603013843, 'acc': 100.0, 'step': 1676},\n",
       " {'loss': 0.0002150304935639724, 'acc': 100.0, 'step': 1677},\n",
       " {'loss': 0.0001805392384994775, 'acc': 100.0, 'step': 1678},\n",
       " {'loss': 7.248734618769959e-05, 'acc': 100.0, 'step': 1679},\n",
       " {'loss': 0.0001463904627598822, 'acc': 100.0, 'step': 1680},\n",
       " {'loss': 0.00013172431499697268, 'acc': 100.0, 'step': 1681},\n",
       " {'loss': 8.542279101675376e-05, 'acc': 100.0, 'step': 1682},\n",
       " {'loss': 0.0002500405826140195, 'acc': 100.0, 'step': 1683},\n",
       " {'loss': 0.00010358299186918885, 'acc': 100.0, 'step': 1684},\n",
       " {'loss': 0.0002782325027510524, 'acc': 100.0, 'step': 1685},\n",
       " {'loss': 0.00012628341210074723, 'acc': 100.0, 'step': 1686},\n",
       " {'loss': 0.00013611381291411817, 'acc': 100.0, 'step': 1687},\n",
       " {'loss': 0.00017214393301401287, 'acc': 100.0, 'step': 1688},\n",
       " {'loss': 0.00013249415496829897, 'acc': 100.0, 'step': 1689},\n",
       " {'loss': 0.00011638963769655675, 'acc': 100.0, 'step': 1690},\n",
       " {'loss': 0.00012972175318282098, 'acc': 100.0, 'step': 1691},\n",
       " {'loss': 0.00018967942742165178, 'acc': 100.0, 'step': 1692},\n",
       " {'loss': 0.00013447977835312486, 'acc': 100.0, 'step': 1693},\n",
       " {'loss': 0.00011538864782778546, 'acc': 100.0, 'step': 1694},\n",
       " {'loss': 0.0003237243217881769, 'acc': 100.0, 'step': 1695},\n",
       " {'loss': 0.00023067387519404292, 'acc': 100.0, 'step': 1696},\n",
       " {'loss': 0.00011204846668988466, 'acc': 100.0, 'step': 1697},\n",
       " {'loss': 0.00018749003356788307, 'acc': 100.0, 'step': 1698},\n",
       " {'loss': 0.0002109321067109704, 'acc': 100.0, 'step': 1699},\n",
       " {'loss': 0.00010263628792017698, 'acc': 100.0, 'step': 1700},\n",
       " {'loss': 0.00026171101490035653, 'acc': 100.0, 'step': 1701},\n",
       " {'loss': 0.0002423468540655449, 'acc': 100.0, 'step': 1702},\n",
       " {'loss': 0.00013896418386138976, 'acc': 100.0, 'step': 1703},\n",
       " {'loss': 0.00019616659847088158, 'acc': 100.0, 'step': 1704},\n",
       " {'loss': 0.00011351099237799644, 'acc': 100.0, 'step': 1705},\n",
       " {'loss': 0.0003345844161231071, 'acc': 100.0, 'step': 1706},\n",
       " {'loss': 0.00016499205958098173, 'acc': 100.0, 'step': 1707},\n",
       " {'loss': 9.128313831752166e-05, 'acc': 100.0, 'step': 1708},\n",
       " {'loss': 9.702327224658802e-05, 'acc': 100.0, 'step': 1709},\n",
       " {'loss': 0.00016106794646475464, 'acc': 100.0, 'step': 1710},\n",
       " {'loss': 0.00012434519885573536, 'acc': 100.0, 'step': 1711},\n",
       " {'loss': 0.00015315372729673982, 'acc': 100.0, 'step': 1712},\n",
       " {'loss': 0.0001660343405092135, 'acc': 100.0, 'step': 1713},\n",
       " {'loss': 0.00011865563283208758, 'acc': 100.0, 'step': 1714},\n",
       " {'loss': 0.00030049707856960595, 'acc': 100.0, 'step': 1715},\n",
       " {'loss': 0.00020716703147627413, 'acc': 100.0, 'step': 1716},\n",
       " {'loss': 0.00017061756807379425, 'acc': 100.0, 'step': 1717},\n",
       " {'loss': 0.00011414485197747126, 'acc': 100.0, 'step': 1718},\n",
       " {'loss': 0.0001634065993130207, 'acc': 100.0, 'step': 1719},\n",
       " {'loss': 0.0002463726559653878, 'acc': 100.0, 'step': 1720},\n",
       " {'loss': 0.00011604781320784241, 'acc': 100.0, 'step': 1721},\n",
       " {'loss': 9.072388638742268e-05, 'acc': 100.0, 'step': 1722},\n",
       " {'loss': 0.000194518783246167, 'acc': 100.0, 'step': 1723},\n",
       " {'loss': 0.00010762151214294136, 'acc': 100.0, 'step': 1724},\n",
       " {'loss': 9.32481634663418e-05, 'acc': 100.0, 'step': 1725},\n",
       " {'loss': 0.00011198099673492834, 'acc': 100.0, 'step': 1726},\n",
       " {'loss': 0.00021824095165356994, 'acc': 100.0, 'step': 1727},\n",
       " {'loss': 0.00010803307668538764, 'acc': 100.0, 'step': 1728},\n",
       " {'loss': 7.727812044322491e-05, 'acc': 100.0, 'step': 1729},\n",
       " {'loss': 0.0001526887936051935, 'acc': 100.0, 'step': 1730},\n",
       " {'loss': 0.00025498971808701754, 'acc': 100.0, 'step': 1731},\n",
       " {'loss': 0.00017242436297237873, 'acc': 100.0, 'step': 1732},\n",
       " {'loss': 7.244622247526422e-05, 'acc': 100.0, 'step': 1733},\n",
       " {'loss': 0.00015341141261160374, 'acc': 100.0, 'step': 1734},\n",
       " {'loss': 0.00030588250956498086, 'acc': 100.0, 'step': 1735},\n",
       " {'loss': 0.00019930525741074234, 'acc': 100.0, 'step': 1736},\n",
       " {'loss': 0.00011801504297181964, 'acc': 100.0, 'step': 1737},\n",
       " {'loss': 0.00013528451381716877, 'acc': 100.0, 'step': 1738},\n",
       " {'loss': 0.00020937906811013818, 'acc': 100.0, 'step': 1739},\n",
       " {'loss': 9.962962212739512e-05, 'acc': 100.0, 'step': 1740},\n",
       " {'loss': 0.00012042995513183996, 'acc': 100.0, 'step': 1741},\n",
       " {'loss': 0.00013569848670158535, 'acc': 100.0, 'step': 1742},\n",
       " {'loss': 0.00023758113093208522, 'acc': 100.0, 'step': 1743},\n",
       " {'loss': 0.00016116788901854306, 'acc': 100.0, 'step': 1744},\n",
       " {'loss': 0.0002295981685165316, 'acc': 100.0, 'step': 1745},\n",
       " {'loss': 9.525408677291125e-05, 'acc': 100.0, 'step': 1746},\n",
       " {'loss': 0.00015161313058342785, 'acc': 100.0, 'step': 1747},\n",
       " {'loss': 0.00012718283687718213, 'acc': 100.0, 'step': 1748}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['train'][-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.741226Z",
     "start_time": "2025-06-26T01:45:37.737721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 2.3028473293080047, 'acc': 11.029411764705882, 'step': 0},\n",
       " {'loss': 1.7820837217218735, 'acc': 56.61764705882353, 'step': 500},\n",
       " {'loss': 2.629711691071005, 'acc': 61.029411764705884, 'step': 1000}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['val'][-1000:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制损失曲线和准确率曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.744941Z",
     "start_time": "2025-06-26T01:45:37.741226Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入绘图库\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "def plot_learning_curves1(history):\n",
    "    # 设置中文字体支持\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体\n",
    "    plt.rcParams['axes.unicode_minus'] = False    # 解决负号显示问题\n",
    "\n",
    "    # 创建一个图形，包含两个子图（损失和准确率）\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # 绘制损失曲线\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    ax1.plot(epochs, history['train_loss'], 'b-', label='训练损失')\n",
    "    ax1.plot(epochs, history['val_loss'], 'r-', label='验证损失')\n",
    "    ax1.set_title('训练与验证损失')\n",
    "    ax1.set_xlabel('轮次')\n",
    "    ax1.set_ylabel('损失')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # 绘制准确率曲线\n",
    "    ax2.plot(epochs, history['train_acc'], 'b-', label='训练准确率')\n",
    "    ax2.plot(epochs, history['val_acc'], 'r-', label='验证准确率')\n",
    "    ax2.set_title('训练与验证准确率')\n",
    "    ax2.set_xlabel('轮次')\n",
    "    ax2.set_ylabel('准确率 (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.816716Z",
     "start_time": "2025-06-26T01:45:37.744941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curves(history, sample_step=500)  #横坐标是 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:45:37.818553Z",
     "start_time": "2025-06-26T01:45:37.816716Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:48:40.300725Z",
     "start_time": "2025-06-26T01:48:39.548524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60.661764705882355, 3.000528833445381)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在测试集上评估模型\n",
    "test_accuracy = evaluate_model(model, test_loader, device, loss_fn)\n",
    "test_accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
