{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from classificatiom_model import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from classificatiom_model import evaluate_classification_model as evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Soft\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Soft\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to C:\\Users\\ArkhamCraft/.cache\\torch\\hub\\checkpoints\\inception_v3_google-0cc3c7bd.pth\n",
      "100%|██████████| 104M/104M [01:15<00:00, 1.44MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionNet模型结构:\n",
      "Inception3(\n",
      "  (Conv2d_1a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_2b_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv2d_3b_1x1): BasicConv2d(\n",
      "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (Conv2d_4a_3x3): BasicConv2d(\n",
      "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Mixed_5b): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5c): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_5d): InceptionA(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch5x5_2): BasicConv2d(\n",
      "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6a): InceptionB(\n",
      "    (branch3x3): BasicConv2d(\n",
      "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6b): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6c): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6d): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_6e): InceptionC(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7dbl_5): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AuxLogits): InceptionAux(\n",
      "    (conv0): BasicConv2d(\n",
      "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      "  (Mixed_7a): InceptionD(\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_2): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_3): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch7x7x3_4): BasicConv2d(\n",
      "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7b): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (Mixed_7c): InceptionE(\n",
      "    (branch1x1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3_2b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_1): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_2): BasicConv2d(\n",
      "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3a): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch3x3dbl_3b): BasicConv2d(\n",
      "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch_pool): BasicConv2d(\n",
      "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "\n",
      "InceptionNet模型参数统计:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 149, 149]             864\n",
      "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
      "       BasicConv2d-3         [-1, 32, 149, 149]               0\n",
      "            Conv2d-4         [-1, 32, 147, 147]           9,216\n",
      "       BatchNorm2d-5         [-1, 32, 147, 147]              64\n",
      "       BasicConv2d-6         [-1, 32, 147, 147]               0\n",
      "            Conv2d-7         [-1, 64, 147, 147]          18,432\n",
      "       BatchNorm2d-8         [-1, 64, 147, 147]             128\n",
      "       BasicConv2d-9         [-1, 64, 147, 147]               0\n",
      "        MaxPool2d-10           [-1, 64, 73, 73]               0\n",
      "           Conv2d-11           [-1, 80, 73, 73]           5,120\n",
      "      BatchNorm2d-12           [-1, 80, 73, 73]             160\n",
      "      BasicConv2d-13           [-1, 80, 73, 73]               0\n",
      "           Conv2d-14          [-1, 192, 71, 71]         138,240\n",
      "      BatchNorm2d-15          [-1, 192, 71, 71]             384\n",
      "      BasicConv2d-16          [-1, 192, 71, 71]               0\n",
      "        MaxPool2d-17          [-1, 192, 35, 35]               0\n",
      "           Conv2d-18           [-1, 64, 35, 35]          12,288\n",
      "      BatchNorm2d-19           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-20           [-1, 64, 35, 35]               0\n",
      "           Conv2d-21           [-1, 48, 35, 35]           9,216\n",
      "      BatchNorm2d-22           [-1, 48, 35, 35]              96\n",
      "      BasicConv2d-23           [-1, 48, 35, 35]               0\n",
      "           Conv2d-24           [-1, 64, 35, 35]          76,800\n",
      "      BatchNorm2d-25           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-26           [-1, 64, 35, 35]               0\n",
      "           Conv2d-27           [-1, 64, 35, 35]          12,288\n",
      "      BatchNorm2d-28           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-29           [-1, 64, 35, 35]               0\n",
      "           Conv2d-30           [-1, 96, 35, 35]          55,296\n",
      "      BatchNorm2d-31           [-1, 96, 35, 35]             192\n",
      "      BasicConv2d-32           [-1, 96, 35, 35]               0\n",
      "           Conv2d-33           [-1, 96, 35, 35]          82,944\n",
      "      BatchNorm2d-34           [-1, 96, 35, 35]             192\n",
      "      BasicConv2d-35           [-1, 96, 35, 35]               0\n",
      "           Conv2d-36           [-1, 32, 35, 35]           6,144\n",
      "      BatchNorm2d-37           [-1, 32, 35, 35]              64\n",
      "      BasicConv2d-38           [-1, 32, 35, 35]               0\n",
      "       InceptionA-39          [-1, 256, 35, 35]               0\n",
      "           Conv2d-40           [-1, 64, 35, 35]          16,384\n",
      "      BatchNorm2d-41           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-42           [-1, 64, 35, 35]               0\n",
      "           Conv2d-43           [-1, 48, 35, 35]          12,288\n",
      "      BatchNorm2d-44           [-1, 48, 35, 35]              96\n",
      "      BasicConv2d-45           [-1, 48, 35, 35]               0\n",
      "           Conv2d-46           [-1, 64, 35, 35]          76,800\n",
      "      BatchNorm2d-47           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-48           [-1, 64, 35, 35]               0\n",
      "           Conv2d-49           [-1, 64, 35, 35]          16,384\n",
      "      BatchNorm2d-50           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-51           [-1, 64, 35, 35]               0\n",
      "           Conv2d-52           [-1, 96, 35, 35]          55,296\n",
      "      BatchNorm2d-53           [-1, 96, 35, 35]             192\n",
      "      BasicConv2d-54           [-1, 96, 35, 35]               0\n",
      "           Conv2d-55           [-1, 96, 35, 35]          82,944\n",
      "      BatchNorm2d-56           [-1, 96, 35, 35]             192\n",
      "      BasicConv2d-57           [-1, 96, 35, 35]               0\n",
      "           Conv2d-58           [-1, 64, 35, 35]          16,384\n",
      "      BatchNorm2d-59           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-60           [-1, 64, 35, 35]               0\n",
      "       InceptionA-61          [-1, 288, 35, 35]               0\n",
      "           Conv2d-62           [-1, 64, 35, 35]          18,432\n",
      "      BatchNorm2d-63           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-64           [-1, 64, 35, 35]               0\n",
      "           Conv2d-65           [-1, 48, 35, 35]          13,824\n",
      "      BatchNorm2d-66           [-1, 48, 35, 35]              96\n",
      "      BasicConv2d-67           [-1, 48, 35, 35]               0\n",
      "           Conv2d-68           [-1, 64, 35, 35]          76,800\n",
      "      BatchNorm2d-69           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-70           [-1, 64, 35, 35]               0\n",
      "           Conv2d-71           [-1, 64, 35, 35]          18,432\n",
      "      BatchNorm2d-72           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-73           [-1, 64, 35, 35]               0\n",
      "           Conv2d-74           [-1, 96, 35, 35]          55,296\n",
      "      BatchNorm2d-75           [-1, 96, 35, 35]             192\n",
      "      BasicConv2d-76           [-1, 96, 35, 35]               0\n",
      "           Conv2d-77           [-1, 96, 35, 35]          82,944\n",
      "      BatchNorm2d-78           [-1, 96, 35, 35]             192\n",
      "      BasicConv2d-79           [-1, 96, 35, 35]               0\n",
      "           Conv2d-80           [-1, 64, 35, 35]          18,432\n",
      "      BatchNorm2d-81           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-82           [-1, 64, 35, 35]               0\n",
      "       InceptionA-83          [-1, 288, 35, 35]               0\n",
      "           Conv2d-84          [-1, 384, 17, 17]         995,328\n",
      "      BatchNorm2d-85          [-1, 384, 17, 17]             768\n",
      "      BasicConv2d-86          [-1, 384, 17, 17]               0\n",
      "           Conv2d-87           [-1, 64, 35, 35]          18,432\n",
      "      BatchNorm2d-88           [-1, 64, 35, 35]             128\n",
      "      BasicConv2d-89           [-1, 64, 35, 35]               0\n",
      "           Conv2d-90           [-1, 96, 35, 35]          55,296\n",
      "      BatchNorm2d-91           [-1, 96, 35, 35]             192\n",
      "      BasicConv2d-92           [-1, 96, 35, 35]               0\n",
      "           Conv2d-93           [-1, 96, 17, 17]          82,944\n",
      "      BatchNorm2d-94           [-1, 96, 17, 17]             192\n",
      "      BasicConv2d-95           [-1, 96, 17, 17]               0\n",
      "       InceptionB-96          [-1, 768, 17, 17]               0\n",
      "           Conv2d-97          [-1, 192, 17, 17]         147,456\n",
      "      BatchNorm2d-98          [-1, 192, 17, 17]             384\n",
      "      BasicConv2d-99          [-1, 192, 17, 17]               0\n",
      "          Conv2d-100          [-1, 128, 17, 17]          98,304\n",
      "     BatchNorm2d-101          [-1, 128, 17, 17]             256\n",
      "     BasicConv2d-102          [-1, 128, 17, 17]               0\n",
      "          Conv2d-103          [-1, 128, 17, 17]         114,688\n",
      "     BatchNorm2d-104          [-1, 128, 17, 17]             256\n",
      "     BasicConv2d-105          [-1, 128, 17, 17]               0\n",
      "          Conv2d-106          [-1, 192, 17, 17]         172,032\n",
      "     BatchNorm2d-107          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-108          [-1, 192, 17, 17]               0\n",
      "          Conv2d-109          [-1, 128, 17, 17]          98,304\n",
      "     BatchNorm2d-110          [-1, 128, 17, 17]             256\n",
      "     BasicConv2d-111          [-1, 128, 17, 17]               0\n",
      "          Conv2d-112          [-1, 128, 17, 17]         114,688\n",
      "     BatchNorm2d-113          [-1, 128, 17, 17]             256\n",
      "     BasicConv2d-114          [-1, 128, 17, 17]               0\n",
      "          Conv2d-115          [-1, 128, 17, 17]         114,688\n",
      "     BatchNorm2d-116          [-1, 128, 17, 17]             256\n",
      "     BasicConv2d-117          [-1, 128, 17, 17]               0\n",
      "          Conv2d-118          [-1, 128, 17, 17]         114,688\n",
      "     BatchNorm2d-119          [-1, 128, 17, 17]             256\n",
      "     BasicConv2d-120          [-1, 128, 17, 17]               0\n",
      "          Conv2d-121          [-1, 192, 17, 17]         172,032\n",
      "     BatchNorm2d-122          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-123          [-1, 192, 17, 17]               0\n",
      "          Conv2d-124          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-125          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-126          [-1, 192, 17, 17]               0\n",
      "      InceptionC-127          [-1, 768, 17, 17]               0\n",
      "          Conv2d-128          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-129          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-130          [-1, 192, 17, 17]               0\n",
      "          Conv2d-131          [-1, 160, 17, 17]         122,880\n",
      "     BatchNorm2d-132          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-133          [-1, 160, 17, 17]               0\n",
      "          Conv2d-134          [-1, 160, 17, 17]         179,200\n",
      "     BatchNorm2d-135          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-136          [-1, 160, 17, 17]               0\n",
      "          Conv2d-137          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-138          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-139          [-1, 192, 17, 17]               0\n",
      "          Conv2d-140          [-1, 160, 17, 17]         122,880\n",
      "     BatchNorm2d-141          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-142          [-1, 160, 17, 17]               0\n",
      "          Conv2d-143          [-1, 160, 17, 17]         179,200\n",
      "     BatchNorm2d-144          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-145          [-1, 160, 17, 17]               0\n",
      "          Conv2d-146          [-1, 160, 17, 17]         179,200\n",
      "     BatchNorm2d-147          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-148          [-1, 160, 17, 17]               0\n",
      "          Conv2d-149          [-1, 160, 17, 17]         179,200\n",
      "     BatchNorm2d-150          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-151          [-1, 160, 17, 17]               0\n",
      "          Conv2d-152          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-153          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-154          [-1, 192, 17, 17]               0\n",
      "          Conv2d-155          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-156          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-157          [-1, 192, 17, 17]               0\n",
      "      InceptionC-158          [-1, 768, 17, 17]               0\n",
      "          Conv2d-159          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-160          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-161          [-1, 192, 17, 17]               0\n",
      "          Conv2d-162          [-1, 160, 17, 17]         122,880\n",
      "     BatchNorm2d-163          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-164          [-1, 160, 17, 17]               0\n",
      "          Conv2d-165          [-1, 160, 17, 17]         179,200\n",
      "     BatchNorm2d-166          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-167          [-1, 160, 17, 17]               0\n",
      "          Conv2d-168          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-169          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-170          [-1, 192, 17, 17]               0\n",
      "          Conv2d-171          [-1, 160, 17, 17]         122,880\n",
      "     BatchNorm2d-172          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-173          [-1, 160, 17, 17]               0\n",
      "          Conv2d-174          [-1, 160, 17, 17]         179,200\n",
      "     BatchNorm2d-175          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-176          [-1, 160, 17, 17]               0\n",
      "          Conv2d-177          [-1, 160, 17, 17]         179,200\n",
      "     BatchNorm2d-178          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-179          [-1, 160, 17, 17]               0\n",
      "          Conv2d-180          [-1, 160, 17, 17]         179,200\n",
      "     BatchNorm2d-181          [-1, 160, 17, 17]             320\n",
      "     BasicConv2d-182          [-1, 160, 17, 17]               0\n",
      "          Conv2d-183          [-1, 192, 17, 17]         215,040\n",
      "     BatchNorm2d-184          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-185          [-1, 192, 17, 17]               0\n",
      "          Conv2d-186          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-187          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-188          [-1, 192, 17, 17]               0\n",
      "      InceptionC-189          [-1, 768, 17, 17]               0\n",
      "          Conv2d-190          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-191          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-192          [-1, 192, 17, 17]               0\n",
      "          Conv2d-193          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-194          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-195          [-1, 192, 17, 17]               0\n",
      "          Conv2d-196          [-1, 192, 17, 17]         258,048\n",
      "     BatchNorm2d-197          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-198          [-1, 192, 17, 17]               0\n",
      "          Conv2d-199          [-1, 192, 17, 17]         258,048\n",
      "     BatchNorm2d-200          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-201          [-1, 192, 17, 17]               0\n",
      "          Conv2d-202          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-203          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-204          [-1, 192, 17, 17]               0\n",
      "          Conv2d-205          [-1, 192, 17, 17]         258,048\n",
      "     BatchNorm2d-206          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-207          [-1, 192, 17, 17]               0\n",
      "          Conv2d-208          [-1, 192, 17, 17]         258,048\n",
      "     BatchNorm2d-209          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-210          [-1, 192, 17, 17]               0\n",
      "          Conv2d-211          [-1, 192, 17, 17]         258,048\n",
      "     BatchNorm2d-212          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-213          [-1, 192, 17, 17]               0\n",
      "          Conv2d-214          [-1, 192, 17, 17]         258,048\n",
      "     BatchNorm2d-215          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-216          [-1, 192, 17, 17]               0\n",
      "          Conv2d-217          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-218          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-219          [-1, 192, 17, 17]               0\n",
      "      InceptionC-220          [-1, 768, 17, 17]               0\n",
      "          Conv2d-221            [-1, 128, 5, 5]          98,304\n",
      "     BatchNorm2d-222            [-1, 128, 5, 5]             256\n",
      "     BasicConv2d-223            [-1, 128, 5, 5]               0\n",
      "          Conv2d-224            [-1, 768, 1, 1]       2,457,600\n",
      "     BatchNorm2d-225            [-1, 768, 1, 1]           1,536\n",
      "     BasicConv2d-226            [-1, 768, 1, 1]               0\n",
      "          Linear-227                 [-1, 1000]         769,000\n",
      "    InceptionAux-228                 [-1, 1000]               0\n",
      "          Conv2d-229          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-230          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-231          [-1, 192, 17, 17]               0\n",
      "          Conv2d-232            [-1, 320, 8, 8]         552,960\n",
      "     BatchNorm2d-233            [-1, 320, 8, 8]             640\n",
      "     BasicConv2d-234            [-1, 320, 8, 8]               0\n",
      "          Conv2d-235          [-1, 192, 17, 17]         147,456\n",
      "     BatchNorm2d-236          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-237          [-1, 192, 17, 17]               0\n",
      "          Conv2d-238          [-1, 192, 17, 17]         258,048\n",
      "     BatchNorm2d-239          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-240          [-1, 192, 17, 17]               0\n",
      "          Conv2d-241          [-1, 192, 17, 17]         258,048\n",
      "     BatchNorm2d-242          [-1, 192, 17, 17]             384\n",
      "     BasicConv2d-243          [-1, 192, 17, 17]               0\n",
      "          Conv2d-244            [-1, 192, 8, 8]         331,776\n",
      "     BatchNorm2d-245            [-1, 192, 8, 8]             384\n",
      "     BasicConv2d-246            [-1, 192, 8, 8]               0\n",
      "      InceptionD-247           [-1, 1280, 8, 8]               0\n",
      "          Conv2d-248            [-1, 320, 8, 8]         409,600\n",
      "     BatchNorm2d-249            [-1, 320, 8, 8]             640\n",
      "     BasicConv2d-250            [-1, 320, 8, 8]               0\n",
      "          Conv2d-251            [-1, 384, 8, 8]         491,520\n",
      "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-253            [-1, 384, 8, 8]               0\n",
      "          Conv2d-254            [-1, 384, 8, 8]         442,368\n",
      "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-256            [-1, 384, 8, 8]               0\n",
      "          Conv2d-257            [-1, 384, 8, 8]         442,368\n",
      "     BatchNorm2d-258            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-259            [-1, 384, 8, 8]               0\n",
      "          Conv2d-260            [-1, 448, 8, 8]         573,440\n",
      "     BatchNorm2d-261            [-1, 448, 8, 8]             896\n",
      "     BasicConv2d-262            [-1, 448, 8, 8]               0\n",
      "          Conv2d-263            [-1, 384, 8, 8]       1,548,288\n",
      "     BatchNorm2d-264            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-265            [-1, 384, 8, 8]               0\n",
      "          Conv2d-266            [-1, 384, 8, 8]         442,368\n",
      "     BatchNorm2d-267            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-268            [-1, 384, 8, 8]               0\n",
      "          Conv2d-269            [-1, 384, 8, 8]         442,368\n",
      "     BatchNorm2d-270            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-271            [-1, 384, 8, 8]               0\n",
      "          Conv2d-272            [-1, 192, 8, 8]         245,760\n",
      "     BatchNorm2d-273            [-1, 192, 8, 8]             384\n",
      "     BasicConv2d-274            [-1, 192, 8, 8]               0\n",
      "      InceptionE-275           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-276            [-1, 320, 8, 8]         655,360\n",
      "     BatchNorm2d-277            [-1, 320, 8, 8]             640\n",
      "     BasicConv2d-278            [-1, 320, 8, 8]               0\n",
      "          Conv2d-279            [-1, 384, 8, 8]         786,432\n",
      "     BatchNorm2d-280            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-281            [-1, 384, 8, 8]               0\n",
      "          Conv2d-282            [-1, 384, 8, 8]         442,368\n",
      "     BatchNorm2d-283            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-284            [-1, 384, 8, 8]               0\n",
      "          Conv2d-285            [-1, 384, 8, 8]         442,368\n",
      "     BatchNorm2d-286            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-287            [-1, 384, 8, 8]               0\n",
      "          Conv2d-288            [-1, 448, 8, 8]         917,504\n",
      "     BatchNorm2d-289            [-1, 448, 8, 8]             896\n",
      "     BasicConv2d-290            [-1, 448, 8, 8]               0\n",
      "          Conv2d-291            [-1, 384, 8, 8]       1,548,288\n",
      "     BatchNorm2d-292            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-293            [-1, 384, 8, 8]               0\n",
      "          Conv2d-294            [-1, 384, 8, 8]         442,368\n",
      "     BatchNorm2d-295            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-296            [-1, 384, 8, 8]               0\n",
      "          Conv2d-297            [-1, 384, 8, 8]         442,368\n",
      "     BatchNorm2d-298            [-1, 384, 8, 8]             768\n",
      "     BasicConv2d-299            [-1, 384, 8, 8]               0\n",
      "          Conv2d-300            [-1, 192, 8, 8]         393,216\n",
      "     BatchNorm2d-301            [-1, 192, 8, 8]             384\n",
      "     BasicConv2d-302            [-1, 192, 8, 8]               0\n",
      "      InceptionE-303           [-1, 2048, 8, 8]               0\n",
      "AdaptiveAvgPool2d-304           [-1, 2048, 1, 1]               0\n",
      "         Dropout-305           [-1, 2048, 1, 1]               0\n",
      "          Linear-306                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 27,161,264\n",
      "Trainable params: 27,161,264\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.02\n",
      "Forward/backward pass size (MB): 228.66\n",
      "Params size (MB): 103.61\n",
      "Estimated Total Size (MB): 333.29\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'inception_model.png'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models  # 导入PyTorch视觉模型库\n",
    "# 导入必要的库\n",
    "import torch.nn as nn  # 导入神经网络模块\n",
    "import torchvision.models as models  # 重复导入，可以删除\n",
    "from torchsummary import torchsummary  # 导入模型可视化工具，用于显示模型参数统计\n",
    "from torchviz import make_dot  # 导入模型可视化工具，用于生成模型结构图\n",
    "\n",
    "# 加载预训练的InceptionNet模型（Inception v3）\n",
    "# pretrained=True表示加载在ImageNet上预训练的权重\n",
    "inception_model = models.inception_v3(pretrained=True)\n",
    "\n",
    "# 打印模型结构，显示所有层和连接\n",
    "print(\"InceptionNet模型结构:\")\n",
    "print(inception_model)\n",
    "\n",
    "# 将模型移至GPU（如果可用）以加速计算，否则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inception_model = inception_model.to(device)\n",
    "\n",
    "# 使用torchsummary打印模型参数统计信息（层数、参数量等）\n",
    "print(\"\\nInceptionNet模型参数统计:\")\n",
    "torchsummary.summary(inception_model, (3, 299, 299))  # Inception v3需要299x299的输入图像，3表示RGB三通道\n",
    "\n",
    "# 创建一个随机输入张量来可视化模型\n",
    "# 设置模型为评估模式以避免批归一化层的错误\n",
    "inception_model.eval()  # 将模型设置为评估模式，关闭dropout等训练特有操作\n",
    "with torch.no_grad():  # 不计算梯度，节省内存\n",
    "    dummy_input = torch.randn(1, 3, 299, 299).to(device)  # 创建一个随机输入张量，模拟一张299x299的RGB图像\n",
    "    output = inception_model(dummy_input)  # 前向传播，获取模型输出\n",
    "\n",
    "# 使用torchviz可视化模型结构并保存为图片\n",
    "# 修复AttributeError: 'Tensor' object has no attribute 'logits'\n",
    "# Inception v3在eval模式下直接返回tensor而不是包含logits属性的对象\n",
    "model_graph = make_dot(output, params=dict(inception_model.named_parameters()))  # 创建计算图可视化对象\n",
    "model_graph.render(\"inception_model\", format=\"png\")  # 渲染并保存为PNG图片\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "token = {\"username\":\"eviltrashcan\",\"key\":\"5a0836e4ef86086fdadf624206bd1421\"}\n",
    "with open('/content/kaggle.json', 'w') as file:\n",
    "  json.dump(token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /content/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp /content/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle config set -n path -v /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /content/competitions/cifar-10/cifar-10.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install py7zr\n",
    "import py7zr\n",
    "a =py7zr.SevenZipFile(r'./train.7z','r')\n",
    "a.extractall(path=r'./competitions/cifar-10/')\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls competitions/cifar-10/train|wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完整数据集大小: 50000\n",
      "训练集大小: 45000\n",
      "验证集大小: 5000\n"
     ]
    }
   ],
   "source": [
    "# 加载CIFAR-10数据集\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 定义CIFAR-10数据集类\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_file, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取标签文件，read_csv默认读取第一行作为列名\n",
    "        self.labels_df = pd.read_csv(labels_file)\n",
    "        self.img_names = self.labels_df.iloc[:, 0].values.astype(str)  # 第一列是图片名称，确保为字符串类型\n",
    "\n",
    "        # 类别名称字典，使用字典可以提高查找速度\n",
    "        self.class_names_dict = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3,\n",
    "                                 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "        # 将文本标签转换为数字ID\n",
    "        self.labels = [self.class_names_dict[label] for label in self.labels_df.iloc[:, 1].values]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx] + '.png') #图片路径\n",
    "        image = Image.open(img_path) #打开图片\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image)\n",
    "\n",
    "        return image_tensor, label\n",
    "\n",
    "# 定义数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4917, 0.4823, 0.4467), (0.2024, 0.1995, 0.2010))\n",
    "])\n",
    "\n",
    "# colab加载CIFAR-10数据集\n",
    "# img_dir = r\"competitions/cifar-10/train\"\n",
    "# labels_file = r\"./trainLabels.csv\"\n",
    "\n",
    "img_dir = r\"D:\\BaiduNetdiskDownload\\1.Python11期\\深度学习代码\\cifar-10\\train\"\n",
    "labels_file = r\"D:\\BaiduNetdiskDownload\\1.Python11期\\深度学习代码\\cifar-10\\trainLabels.csv\"\n",
    "full_dataset = CIFAR10Dataset(img_dir=img_dir, labels_file=labels_file, transform=transform)\n",
    "\n",
    "# 定义类别名称\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_size = 45000\n",
    "val_size = 5000\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "# 查看数据集基本信息\n",
    "print(f\"完整数据集大小: {len(full_dataset)}\")\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"验证集大小: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomInceptionNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (inception3a): InceptionModule(\n",
      "    (branch1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (branch2): Sequential(\n",
      "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (inception3b): InceptionModule(\n",
      "    (branch1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (branch2): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (inception4a): InceptionModule(\n",
      "    (branch1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (branch2): Sequential(\n",
      "      (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (inception4b): InceptionModule(\n",
      "    (branch1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (branch2): Sequential(\n",
      "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 自定义InceptionNet模型\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义Inception模块\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj):\n",
    "        \"\"\"\n",
    "        Inception模块初始化\n",
    "        \n",
    "        参数:\n",
    "            in_channels: 输入通道数\n",
    "            ch1x1: 1x1卷积分支的输出通道数\n",
    "            ch3x3red: 3x3卷积分支中1x1卷积的输出通道数(降维)\n",
    "            ch3x3: 3x3卷积分支中3x3卷积的输出通道数\n",
    "            ch5x5red: 5x5卷积分支中1x1卷积的输出通道数(降维)\n",
    "            ch5x5: 5x5卷积分支中5x5卷积的输出通道数\n",
    "            pool_proj: 池化分支中1x1卷积的输出通道数\n",
    "        \"\"\"\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        # 1x1卷积分支 - 直接进行特征提取和降维\n",
    "        self.branch1 = nn.Conv2d(in_channels, ch1x1, kernel_size=1)\n",
    "        \n",
    "        # 1x1卷积 -> 3x3卷积分支 - 先降维再提取特征\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch3x3red, kernel_size=1),  # 降维\n",
    "            nn.ReLU(inplace=True),  # 激活函数\n",
    "            nn.Conv2d(ch3x3red, ch3x3, kernel_size=3, padding=1)  # 特征提取\n",
    "        )\n",
    "        \n",
    "        # 1x1卷积 -> 5x5卷积分支 - 先降维再提取更大感受野的特征\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch5x5red, kernel_size=1),  # 降维\n",
    "            nn.ReLU(inplace=True),  # 激活函数\n",
    "            nn.Conv2d(ch5x5red, ch5x5, kernel_size=5, padding=2)  # 大感受野特征提取\n",
    "        )\n",
    "        \n",
    "        # 3x3池化 -> 1x1卷积分支 - 先池化再降维\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),  # 池化提取主要特征\n",
    "            nn.Conv2d(in_channels, pool_proj, kernel_size=1)  # 降维\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播函数\"\"\"\n",
    "        # 对每个分支进行计算并应用ReLU激活函数\n",
    "        branch1 = F.relu(self.branch1(x))\n",
    "        branch2 = F.relu(self.branch2(x))\n",
    "        branch3 = F.relu(self.branch3(x))\n",
    "        branch4 = F.relu(self.branch4(x))\n",
    "        \n",
    "        # 在通道维度上拼接所有分支的输出，形成多尺度特征表示\n",
    "        return torch.cat([branch1, branch2, branch3, branch4], 1)\n",
    "\n",
    "# 定义自定义的InceptionNet模型\n",
    "class CustomInceptionNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        \"\"\"\n",
    "        自定义InceptionNet模型初始化\n",
    "        \n",
    "        参数:\n",
    "            num_classes: 分类类别数，默认为10\n",
    "        \"\"\"\n",
    "        super(CustomInceptionNet, self).__init__()\n",
    "        \n",
    "        # 初始卷积层 - 提取基础特征\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)  # 输入图像为3通道\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 降低分辨率\n",
    "        \n",
    "        # 卷积层 - 进一步提取特征\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)  # 1x1卷积进行通道整合\n",
    "        self.conv3 = nn.Conv2d(64, 192, kernel_size=3, padding=1)  # 3x3卷积提取特征\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 再次降低分辨率\n",
    "        \n",
    "        # Inception模块 - 多尺度特征提取\n",
    "        # 第一组Inception模块\n",
    "        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)  # 输入192通道，输出256通道\n",
    "        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)  # 输入256通道，输出480通道\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 降低分辨率\n",
    "        \n",
    "        # 第二组Inception模块\n",
    "        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)  # 输入480通道，输出512通道\n",
    "        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)  # 输入512通道，输出512通道\n",
    "        \n",
    "        # 全局平均池化 - 将特征图转换为特征向量\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # 自适应平均池化到1x1\n",
    "        \n",
    "        # 分类器\n",
    "        self.dropout = nn.Dropout(0.4)  # 防止过拟合\n",
    "        self.fc = nn.Linear(512, num_classes)  # 全连接层进行分类\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播函数\"\"\"\n",
    "        # 初始层处理\n",
    "        x = F.relu(self.conv1(x))  # 应用激活函数\n",
    "        x = self.maxpool1(x)  # 池化\n",
    "        \n",
    "        # 卷积层处理\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # Inception模块处理\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        \n",
    "        # 全局平均池化\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)  # 展平特征图为一维向量\n",
    "        \n",
    "        # 分类器\n",
    "        x = self.dropout(x)  # 应用dropout\n",
    "        x = self.fc(x)  # 全连接层分类\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 创建自定义InceptionNet模型实例\n",
    "model = CustomInceptionNet(num_classes=10)  # 创建10分类的模型实例\n",
    "\n",
    "print(model)  # 打印模型结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次图像形状: torch.Size([64, 3, 32, 32])\n",
      "批次标签形状: torch.Size([64])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# 从train_loader获取第一个批次的数据\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 查看批次数据的形状\n",
    "print(\"批次图像形状:\", images.shape)\n",
    "print(\"批次标签形状:\", labels.shape)\n",
    "\n",
    "\n",
    "print('-'*100)\n",
    "# 进行前向传播\n",
    "with torch.no_grad():  # 不需要计算梯度\n",
    "    outputs = model(images)\n",
    "\n",
    "\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要求梯度的参数总量: 1507314\n",
      "模型总参数量: 1507314\n",
      "\n",
      "各层参数量明细:\n",
      "conv1.weight: 9408 参数\n",
      "conv1.bias: 64 参数\n",
      "conv2.weight: 4096 参数\n",
      "conv2.bias: 64 参数\n",
      "conv3.weight: 110592 参数\n",
      "conv3.bias: 192 参数\n",
      "inception3a.branch1.weight: 12288 参数\n",
      "inception3a.branch1.bias: 64 参数\n",
      "inception3a.branch2.0.weight: 18432 参数\n",
      "inception3a.branch2.0.bias: 96 参数\n",
      "inception3a.branch2.2.weight: 110592 参数\n",
      "inception3a.branch2.2.bias: 128 参数\n",
      "inception3a.branch3.0.weight: 3072 参数\n",
      "inception3a.branch3.0.bias: 16 参数\n",
      "inception3a.branch3.2.weight: 12800 参数\n",
      "inception3a.branch3.2.bias: 32 参数\n",
      "inception3a.branch4.1.weight: 6144 参数\n",
      "inception3a.branch4.1.bias: 32 参数\n",
      "inception3b.branch1.weight: 32768 参数\n",
      "inception3b.branch1.bias: 128 参数\n",
      "inception3b.branch2.0.weight: 32768 参数\n",
      "inception3b.branch2.0.bias: 128 参数\n",
      "inception3b.branch2.2.weight: 221184 参数\n",
      "inception3b.branch2.2.bias: 192 参数\n",
      "inception3b.branch3.0.weight: 8192 参数\n",
      "inception3b.branch3.0.bias: 32 参数\n",
      "inception3b.branch3.2.weight: 76800 参数\n",
      "inception3b.branch3.2.bias: 96 参数\n",
      "inception3b.branch4.1.weight: 16384 参数\n",
      "inception3b.branch4.1.bias: 64 参数\n",
      "inception4a.branch1.weight: 92160 参数\n",
      "inception4a.branch1.bias: 192 参数\n",
      "inception4a.branch2.0.weight: 46080 参数\n",
      "inception4a.branch2.0.bias: 96 参数\n",
      "inception4a.branch2.2.weight: 179712 参数\n",
      "inception4a.branch2.2.bias: 208 参数\n",
      "inception4a.branch3.0.weight: 7680 参数\n",
      "inception4a.branch3.0.bias: 16 参数\n",
      "inception4a.branch3.2.weight: 19200 参数\n",
      "inception4a.branch3.2.bias: 48 参数\n",
      "inception4a.branch4.1.weight: 30720 参数\n",
      "inception4a.branch4.1.bias: 64 参数\n",
      "inception4b.branch1.weight: 81920 参数\n",
      "inception4b.branch1.bias: 160 参数\n",
      "inception4b.branch2.0.weight: 57344 参数\n",
      "inception4b.branch2.0.bias: 112 参数\n",
      "inception4b.branch2.2.weight: 225792 参数\n",
      "inception4b.branch2.2.bias: 224 参数\n",
      "inception4b.branch3.0.weight: 12288 参数\n",
      "inception4b.branch3.0.bias: 24 参数\n",
      "inception4b.branch3.2.weight: 38400 参数\n",
      "inception4b.branch3.2.bias: 64 参数\n",
      "inception4b.branch4.1.weight: 32768 参数\n",
      "inception4b.branch4.1.bias: 64 参数\n",
      "fc.weight: 5120 参数\n",
      "fc.bias: 10 参数\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数量\n",
    "# 统计需要求梯度的参数总量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"需要求梯度的参数总量: {total_params}\")\n",
    "\n",
    "# 统计所有参数总量\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {all_params}\")\n",
    "\n",
    "# 查看每层参数量明细\n",
    "print(\"\\n各层参数量明细:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} 参数\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数，适用于多分类问题，里边会做softmax，还有会把0-9标签转换成one-hot编码\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD优化器，学习率为0.01，动量为0.9\n",
    "print(\"损失函数:\", loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a552305c6e9401f8047a87f54d91636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/35200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m early_stopping\u001b[38;5;241m=\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      5\u001b[0m model_saver\u001b[38;5;241m=\u001b[39mModelSaver(save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classification_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_saver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_saver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\Python_Code\\ai_train\\day33\\classificatiom_model.py:225\u001b[0m, in \u001b[0;36mtrain_classification_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, tensorboard_logger, model_saver, early_stopping, eval_step)\u001b[0m\n\u001b[0;32m    218\u001b[0m record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_value, \n\u001b[0;32m    220\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc, \n\u001b[0;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m: global_step\n\u001b[0;32m    222\u001b[0m })\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m eval_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 225\u001b[0m     val_acc, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_classification_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_loss, \n\u001b[0;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_acc, \n\u001b[0;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m: global_step\n\u001b[0;32m    230\u001b[0m     })\n\u001b[0;32m    231\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32md:\\Code\\Python_Code\\ai_train\\day33\\classificatiom_model.py:127\u001b[0m, in \u001b[0;36mevaluate_classification_model\u001b[1;34m(model, test_loader, device, criterion)\u001b[0m\n\u001b[0;32m    123\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# 不计算梯度\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# 遍历测试数据集中的每一批数据\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 将数据转移到指定设备(GPU/CPU)\u001b[39;49;00m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 前向传播得到模型输出\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m, in \u001b[0;36mCIFAR10Dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     29\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 32\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image_tensor, label\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torchvision\\transforms\\functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[0;32m    167\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mbyteorder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlittle\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16B\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[1;32m--> 168\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    171\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\PIL\\Image.py:747\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    745\u001b[0m     new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 747\u001b[0m     new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    748\u001b[0m new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m], new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtypestr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _conv_type_shape(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\PIL\\Image.py:796\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m encoder_args \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m    794\u001b[0m     encoder_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m--> 796\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\PIL\\ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "model = model.to(device) #将模型移动到GPU\n",
    "early_stopping=EarlyStopping(patience=5, delta=0.001)\n",
    "model_saver=ModelSaver(save_dir='model_weights', save_best_only=True)\n",
    "\n",
    "\n",
    "model, history = train_classification_model(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=50, early_stopping=early_stopping, model_saver=model_saver, tensorboard_logger=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['train'][-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['val'][-1000:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history, sample_step=500)  #横坐标是 steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
