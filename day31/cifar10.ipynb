{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from classificatiom_model import EarlyStopping, ModelSaver,train_classification_model,plot_learning_curves\n",
    "from classificatiom_model import evaluate_classification_model as evaluate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 45000\n",
      "验证集大小: 5000\n"
     ]
    }
   ],
   "source": [
    "# 加载CIFAR-10数据集\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 定义CIFAR-10数据集类\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, img_dir, labels_df, transform=None):\n",
    "        \"\"\"\n",
    "        初始化CIFAR-10数据集\n",
    "        \n",
    "        参数:\n",
    "            img_dir: 图片目录路径\n",
    "            labels_df: 包含标签信息的DataFrame\n",
    "            transform: 图像预处理转换\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir  # 存储图片目录路径\n",
    "        self.transform = transform  # 存储图像转换操作\n",
    "        \n",
    "        self.labels_df = labels_df  # 存储标签DataFrame\n",
    "        self.img_names = self.labels_df.iloc[:, 0].values.astype(str)  # 第一列是图片名称，确保为字符串类型\n",
    "        \n",
    "        # 类别名称字典，使用字典可以提高查找速度\n",
    "        self.class_names_dict = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, \n",
    "                                 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
    "        # 将文本标签转换为数字ID\n",
    "        self.labels = [self.class_names_dict[label] for label in self.labels_df.iloc[:, 1].values]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集中样本的数量\"\"\"\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的样本\n",
    "        \n",
    "        参数:\n",
    "            idx: 样本索引\n",
    "            \n",
    "        返回:\n",
    "            image_tensor: 经过转换的图像张量\n",
    "            label: 对应的标签\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx] + '.png')  # 构建图片完整路径\n",
    "        image = Image.open(img_path)  # 打开图片\n",
    "        label = self.labels[idx]  # 获取对应标签\n",
    "        \n",
    "        if self.transform:\n",
    "            image_tensor = self.transform(image)  # 应用图像转换\n",
    "            \n",
    "        return image_tensor, label\n",
    "\n",
    "# 读取标签文件\n",
    "img_dir = r\"D:\\BaiduNetdiskDownload\\1.Python11期\\深度学习代码\\cifar-10\\train\"  # 图片目录路径\n",
    "labels_file = r\"D:\\BaiduNetdiskDownload\\1.Python11期\\深度学习代码\\cifar-10\\trainLabels.csv\"  # 标签文件路径\n",
    "labels_df = pd.read_csv(labels_file)  # 读取CSV标签文件\n",
    "\n",
    "# 划分数据集为训练集和验证集\n",
    "train_size = 45000  # 训练集大小\n",
    "val_size = 5000  # 验证集大小（总共50000张图片）\n",
    "train_df = labels_df.iloc[:train_size]  # 前45000个样本作为训练集\n",
    "val_df = labels_df.iloc[train_size:]  # 后5000个样本作为验证集\n",
    "\n",
    "# 定义训练集数据预处理（包含图像增强）\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将PIL图像转换为张量，并将像素值归一化到[0,1]\n",
    "    transforms.RandomRotation(40),  # 随机旋转图像，增强数据多样性\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转图像，增强数据多样性\n",
    "    transforms.Normalize((0.4917, 0.4823, 0.4467), (0.2024, 0.1995, 0.2010))  # 使用CIFAR-10的均值和标准差进行标准化\n",
    "])\n",
    "\n",
    "# 定义验证集数据预处理（不做图像增强）\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将PIL图像转换为张量\n",
    "    transforms.Normalize((0.4917, 0.4823, 0.4467), (0.2024, 0.1995, 0.2010))  # 使用相同的均值和标准差进行标准化\n",
    "])\n",
    "\n",
    "# 创建训练集和验证集实例\n",
    "train_dataset = CIFAR10Dataset(img_dir=img_dir, labels_df=train_df, transform=train_transform)\n",
    "val_dataset = CIFAR10Dataset(img_dir=img_dir, labels_df=val_df, transform=val_transform)\n",
    "\n",
    "# 定义类别名称列表，用于结果可视化和分析\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# 查看数据集基本信息\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"验证集大小: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True #打乱数据集，每次迭代时，数据集的顺序都会被打乱\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 第一组卷积层 - 使用Sequential组织\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),  # 输入3通道(RGB)，输出128通道，3x3卷积核，padding保持尺寸不变\n",
    "            nn.BatchNorm2d(128),  # 批量归一化，稳定训练过程\n",
    "            nn.ReLU(),  # 激活函数，引入非线性\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),  # 第二层卷积，保持通道数不变\n",
    "            nn.BatchNorm2d(128),  # 批量归一化\n",
    "            nn.ReLU(),  # 激活函数\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 最大池化，将特征图尺寸减半 (32x32 -> 16x16)\n",
    "        )\n",
    "        \n",
    "        # 第二组卷积层 - 使用Sequential组织\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # 输入128通道，输出256通道，特征维度提升\n",
    "            nn.BatchNorm2d(256),  # 批量归一化\n",
    "            nn.ReLU(),  # 激活函数\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),  # 保持通道数不变\n",
    "            nn.BatchNorm2d(256),  # 批量归一化\n",
    "            nn.ReLU(),  # 激活函数\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 最大池化，将特征图尺寸再次减半 (16x16 -> 8x8)\n",
    "        )\n",
    "        \n",
    "        # 第三组卷积层 - 使用Sequential组织\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),  # 输入256通道，输出512通道，进一步提取高级特征\n",
    "            nn.BatchNorm2d(512),  # 批量归一化\n",
    "            nn.ReLU(),  # 激活函数\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),  # 保持通道数不变\n",
    "            nn.BatchNorm2d(512),  # 批量归一化\n",
    "            nn.ReLU(),  # 激活函数\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 最大池化，将特征图尺寸再次减半 (8x8 -> 4x4)\n",
    "        )\n",
    "        \n",
    "        # 全连接层 - 使用Sequential组织\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 1024),  # 输入维度为512*4*4(展平后的特征图)，输出1024维特征\n",
    "            nn.ReLU(),  # 激活函数\n",
    "            nn.Linear(1024, 10)  # 最终输出层，10个类别对应CIFAR-10数据集\n",
    "        )\n",
    "        \n",
    "        # 初始化权重\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"使用 xavier 均匀分布来初始化卷积层和全连接层的权重\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)  # Xavier初始化，有助于解决深度网络的梯度消失/爆炸问题\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)  # 偏置初始化为0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 前向传播使用Sequential定义的块\n",
    "        x = self.conv_block1(x)  # 第一组卷积操作\n",
    "        x = self.conv_block2(x)  # 第二组卷积操作\n",
    "        x = self.conv_block3(x)  # 第三组卷积操作\n",
    "        \n",
    "        # 展平操作，将三维特征图转为一维向量\n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 512*4*4]\n",
    "        \n",
    "        # 通过分类器得到最终预测结果\n",
    "        x = self.classifier(x)  # [batch_size, 10]\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次图像形状: torch.Size([64, 3, 32, 32])\n",
      "批次标签形状: torch.Size([64])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# 从train_loader获取第一个批次的数据\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 查看批次数据的形状\n",
    "print(\"批次图像形状:\", images.shape)\n",
    "print(\"批次标签形状:\", labels.shape)\n",
    "\n",
    "\n",
    "print('-'*100)\n",
    "# 进行前向传播\n",
    "with torch.no_grad():  # 不需要计算梯度\n",
    "    outputs = model(images)\n",
    "    \n",
    "\n",
    "print(outputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需要求梯度的参数总量: 12979850\n",
      "模型总参数量: 12979850\n",
      "\n",
      "各层参数量明细:\n",
      "conv_block1.0.weight: 3456 参数\n",
      "conv_block1.0.bias: 128 参数\n",
      "conv_block1.1.weight: 128 参数\n",
      "conv_block1.1.bias: 128 参数\n",
      "conv_block1.3.weight: 147456 参数\n",
      "conv_block1.3.bias: 128 参数\n",
      "conv_block1.4.weight: 128 参数\n",
      "conv_block1.4.bias: 128 参数\n",
      "conv_block2.0.weight: 294912 参数\n",
      "conv_block2.0.bias: 256 参数\n",
      "conv_block2.1.weight: 256 参数\n",
      "conv_block2.1.bias: 256 参数\n",
      "conv_block2.3.weight: 589824 参数\n",
      "conv_block2.3.bias: 256 参数\n",
      "conv_block2.4.weight: 256 参数\n",
      "conv_block2.4.bias: 256 参数\n",
      "conv_block3.0.weight: 1179648 参数\n",
      "conv_block3.0.bias: 512 参数\n",
      "conv_block3.1.weight: 512 参数\n",
      "conv_block3.1.bias: 512 参数\n",
      "conv_block3.3.weight: 2359296 参数\n",
      "conv_block3.3.bias: 512 参数\n",
      "conv_block3.4.weight: 512 参数\n",
      "conv_block3.4.bias: 512 参数\n",
      "classifier.0.weight: 8388608 参数\n",
      "classifier.0.bias: 1024 参数\n",
      "classifier.2.weight: 10240 参数\n",
      "classifier.2.bias: 10 参数\n"
     ]
    }
   ],
   "source": [
    "# 计算模型的总参数量\n",
    "# 统计需要求梯度的参数总量\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"需要求梯度的参数总量: {total_params}\")\n",
    "\n",
    "# 统计所有参数总量\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {all_params}\")\n",
    "\n",
    "# 查看每层参数量明细\n",
    "print(\"\\n各层参数量明细:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} 参数\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数: CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "# 定义损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数，适用于多分类问题，里边会做softmax，还有会把0-9标签转换成one-hot编码\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # SGD优化器，学习率为0.01，动量为0.9\n",
    "print(\"损失函数:\", loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7283d86ccde40b3bcccf7e192f22859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/35200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m early_stopping\u001b[38;5;241m=\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      5\u001b[0m model_saver\u001b[38;5;241m=\u001b[39mModelSaver(save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classification_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_saver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_saver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\Python_Code\\ai_train\\day31\\classificatiom_model.py:204\u001b[0m, in \u001b[0;36mtrain_classification_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, tensorboard_logger, model_saver, early_stopping, eval_step)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdatas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 46\u001b[0m, in \u001b[0;36mCIFAR10Dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m获取指定索引的样本\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    label: 对应的标签\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     45\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_names[idx] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 构建图片完整路径\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 打开图片\u001b[39;00m\n\u001b[0;32m     47\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]  \u001b[38;5;66;03m# 获取对应标签\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[1;32md:\\Soft\\Python312\\Lib\\site-packages\\PIL\\Image.py:3465\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3462\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3465\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3466\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "model = model.to(device) #将模型移动到GPU\n",
    "early_stopping=EarlyStopping(patience=5, delta=0.001)\n",
    "model_saver=ModelSaver(save_dir='model_weights', save_best_only=True)\n",
    "\n",
    "\n",
    "model, history = train_classification_model(model, train_loader, val_loader, loss_fn, optimizer, device, num_epochs=50, early_stopping=early_stopping, model_saver=model_saver, tensorboard_logger=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['train'][-100:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['val'][-1000:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history, sample_step=500)  #横坐标是 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'competitions/cifar-10/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m img_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompetitions/cifar-10/test\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 测试图片目录路径\u001b[39;00m\n\u001b[0;32m    105\u001b[0m labels_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sampleSubmission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 提交模板文件路径\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[43mpredict_test_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 调用预测函数，批次大小为128\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 58\u001b[0m, in \u001b[0;36mpredict_test_set\u001b[1;34m(model, img_dir, labels_file, device, batch_size)\u001b[0m\n\u001b[0;32m     52\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     53\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),  \u001b[38;5;66;03m# 将PIL图像转换为张量\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.4917\u001b[39m, \u001b[38;5;241m0.4823\u001b[39m, \u001b[38;5;241m0.4467\u001b[39m), (\u001b[38;5;241m0.2024\u001b[39m, \u001b[38;5;241m0.1995\u001b[39m, \u001b[38;5;241m0.2010\u001b[39m))  \u001b[38;5;66;03m# 使用CIFAR-10的均值和标准差进行标准化\u001b[39;00m\n\u001b[0;32m     55\u001b[0m ])\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# 创建测试数据集和数据加载器\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCIFAR10TestDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 实例化测试数据集\u001b[39;00m\n\u001b[0;32m     59\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)  \u001b[38;5;66;03m# 创建数据加载器，不打乱顺序\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# 设置模型为评估模式\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m, in \u001b[0;36mCIFAR10TestDataset.__init__\u001b[1;34m(self, img_dir, transform)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir \u001b[38;5;241m=\u001b[39m img_dir  \u001b[38;5;66;03m# 存储图片目录路径\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform  \u001b[38;5;66;03m# 存储图像变换操作\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'competitions/cifar-10/test'"
     ]
    }
   ],
   "source": [
    "# 导入所需库\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import tqdm\n",
    "\n",
    "# 定义测试数据集类\n",
    "class CIFAR10TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        初始化测试数据集\n",
    "\n",
    "        参数:\n",
    "            img_dir: 测试图片目录\n",
    "            transform: 图像预处理变换\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir  # 存储图片目录路径\n",
    "        self.transform = transform  # 存储图像变换操作\n",
    "        self.img_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]  # 获取所有PNG格式的图片文件名\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)  # 返回数据集中图片的数量\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])  # 构建完整的图片路径\n",
    "        image = Image.open(img_path).convert('RGB')  # 打开图片并转换为RGB格式\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # 应用图像变换\n",
    "\n",
    "        # 提取图像ID（文件名去掉扩展名）\n",
    "        img_id = int(os.path.splitext(self.img_files[idx])[0])  # 从文件名中提取图像ID\n",
    "\n",
    "        return image, img_id  # 返回图像和对应的ID\n",
    "\n",
    "# 定义预测函数\n",
    "def predict_test_set(model, img_dir, labels_file, device, batch_size=64):\n",
    "    \"\"\"\n",
    "    预测测试集并生成提交文件\n",
    "\n",
    "    参数:\n",
    "        model: 训练好的模型\n",
    "        img_dir: 测试图片目录\n",
    "        labels_file: 提交模板文件路径\n",
    "        device: 计算设备\n",
    "        batch_size: 批处理大小\n",
    "    \"\"\"\n",
    "    # 图像预处理变换（与训练集相同）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # 将PIL图像转换为张量\n",
    "        transforms.Normalize((0.4917, 0.4823, 0.4467), (0.2024, 0.1995, 0.2010))  # 使用CIFAR-10的均值和标准差进行标准化\n",
    "    ])\n",
    "\n",
    "    # 创建测试数据集和数据加载器\n",
    "    test_dataset = CIFAR10TestDataset(img_dir, transform=transform)  # 实例化测试数据集\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)  # 创建数据加载器，不打乱顺序\n",
    "\n",
    "    # 设置模型为评估模式\n",
    "    model.eval()  # 切换到评估模式，禁用dropout等训练特有的层\n",
    "\n",
    "    # 读取提交模板\n",
    "    submission_df = pd.read_csv(labels_file)  # 读取提交模板文件\n",
    "    predictions = {}  # 用于存储预测结果的字典\n",
    "\n",
    "    # 使用tqdm显示进度条\n",
    "    print(\"正在预测测试集...\")\n",
    "    with torch.no_grad():  # 禁用梯度计算，减少内存使用并加速推理\n",
    "        for images, img_ids in tqdm.tqdm(test_loader, desc=\"预测进度\"):  # 遍历测试数据集\n",
    "            images = images.to(device)  # 将图像数据移动到指定设备（CPU或GPU）\n",
    "            outputs = model(images)  # 使用模型进行前向传播，获取输出\n",
    "            _, predicted = torch.max(outputs, 1)  # 取最大值的索引作为预测结果\n",
    "\n",
    "            # 记录每个图像的预测结果\n",
    "            for i, img_id in enumerate(img_ids):\n",
    "                predictions[img_id.item()] = predicted[i].item()  # 将张量转换为Python数值并存储\n",
    "\n",
    "    # 定义类别名称\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  # CIFAR-10的10个类别\n",
    "\n",
    "    # 将数值标签转换为类别名称\n",
    "    labeled_predictions = {img_id: class_names[pred] for img_id, pred in predictions.items()}  # 将数字标签映射为类别名称\n",
    "\n",
    "    # 直接创建DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': list(labeled_predictions.keys()),  # 图像ID列\n",
    "        'label': list(labeled_predictions.values())  # 预测的类别名称列\n",
    "    })\n",
    "    # 按id列排序\n",
    "    submission_df = submission_df.sort_values(by='id')  # 确保结果按ID排序\n",
    "\n",
    "    # 检查id列是否有重复值\n",
    "    has_duplicates = submission_df['id'].duplicated().any()  # 检查是否有重复的图像ID\n",
    "    print(f\"id列是否有重复值: {has_duplicates}\")\n",
    "    \n",
    "    # 保存预测结果\n",
    "    output_file = 'cifar10_submission.csv'  # 输出文件名\n",
    "    submission_df.to_csv(output_file, index=False)  # 保存为CSV文件，不包含索引列\n",
    "    print(f\"预测完成，结果已保存至 {output_file}\")\n",
    "\n",
    "# 执行测试集预测\n",
    "img_dir = r\"competitions/cifar-10/test\"  # 测试图片目录路径\n",
    "labels_file = r\"./sampleSubmission.csv\"  # 提交模板文件路径\n",
    "predict_test_set(model, img_dir, labels_file, device, batch_size=128)  # 调用预测函数，批次大小为128\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
